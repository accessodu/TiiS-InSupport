{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e507a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28 ]. form!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from init import *\n",
    "from testURL import *\n",
    "def sortFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    \n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    for tests in soup.findAll('select'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "\n",
    "            if \" \" == tests.text:\n",
    "                sort_inner.append(0)             \n",
    "            else:\n",
    "                #print(tests.text)\n",
    "                if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                    #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                    sort_inner.append(1)\n",
    "                else:\n",
    "                    sort_inner.append(0)             \n",
    "            if('sort' in list(tests.attrs.values())):\n",
    "                #print(tests.attrs.values())\n",
    "                sort_attribute.append(1)\n",
    "            else:\n",
    "                sort_attribute.append(0) \n",
    "            optionTag = tests.findAll(\"option\")\n",
    "            option_tag_attribute_value.append(len(optionTag))\n",
    " \n",
    "    for tests in soup.findAll('ul'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "      \n",
    "            if \" \" == tests.text:\n",
    "                sort_inner.append(0)             \n",
    "            else:\n",
    "                #print(tests.text)\n",
    "                if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                    #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                    sort_inner.append(1)\n",
    "                else:\n",
    "                    sort_inner.append(0)             \n",
    "            if('sort' in list(tests.attrs.values())):\n",
    "                #print(tests.attrs.values())\n",
    "                sort_attribute.append(1)\n",
    "            else:\n",
    "                sort_attribute.append(0) \n",
    "            optionTag = tests.findAll(\"li\")\n",
    "            option_tag_attribute_value.append(len(optionTag))\n",
    "    else:\n",
    "        sort_inner.append(0)\n",
    "        option_tag_attribute_value.append(0)\n",
    "        sort_attribute.append(0)\n",
    "        t_count.append(0)\n",
    "    if (sort_inner ==[]):\n",
    "        sort_inner = [0]\n",
    "    if (sort_attribute ==[]):\n",
    "        sort_attribute = [0]\n",
    "    if (option_tag_attribute_value ==[]):\n",
    "        option_tag_attribute_value = [0]\n",
    "\n",
    "    if (t_count ==[]):\n",
    "        t_count = [0]    \n",
    "    temp = len(sort_inner)*[_url_]\n",
    "    \n",
    "    return temp, sort_inner,  option_tag_attribute_value, sort_attribute,t_count\n",
    "#print(sortFunc(turl[5]))\n",
    "# for i in range(10):\n",
    "#      print([i],sortFunc(turl[i]))\n",
    "def get_class_data(searchQ) :\n",
    "        name_url, sort_inner, option_tag_attribute_value, sort_attribute, textCount = sortFunc(searchQ)\n",
    "        sort_inner = str(sort_inner)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        sort_attribute = str(sort_attribute)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #option_tag_attribute_value = str(option_tag_attribute_value)[1:-1]\n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in sort_inner:\n",
    "            sort_inner = i\n",
    "            temp.append([sort_inner])        \n",
    "        \n",
    "        t_sort_attribute = []\n",
    "        for m in sort_attribute:\n",
    "            t_sort_attribute.append(m)\n",
    "        arr2d = np.matrix(temp)\n",
    "        column_to_add = np.array(t_sort_attribute)\n",
    "        output = np.column_stack((arr2d, column_to_add))\n",
    "        f_sort_attribute = output.tolist()\n",
    "        \n",
    "        t_option = []\n",
    "        for m in option_tag_attribute_value:\n",
    "            t_option.append(m)\n",
    "        option_arr2d = np.matrix(f_sort_attribute)\n",
    "        option_to_add = np.array(t_option)\n",
    "        output_option = np.column_stack((option_arr2d, option_to_add))\n",
    "        f_option = output_option.tolist()\n",
    "    \n",
    "        t_textCount = []\n",
    "        for m in textCount:\n",
    "            t_textCount.append(m)\n",
    "        textCount_arr2d = np.matrix(f_option)\n",
    "        textCount_add = np.array(t_textCount)\n",
    "        textCount_output = np.column_stack((textCount_arr2d, textCount_add))\n",
    "        f_textCount = textCount_output.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_textCount)\n",
    "        column_name = np.array(t_name)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "\n",
    "        return f_name\n",
    "#get_class_data(turl[3])\n",
    "def write_header():\n",
    "    list_of_header = [\"sort_inner\", \"sort_attribute\", \"option_tag_attribute_value\",\"sortClass\",\"textCount\",\"name_url\"]\n",
    "    save_path = 'result/sort/'\n",
    "    file_name = \"sort_test__1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/sort/'\n",
    "    file_name = \"sort_test__1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a73674",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/sort_test_set_1.csv'\n",
    "sort_csv_df = pd.read_csv(sort_searchpath)\n",
    "sort_X_test = sort_csv_df[['sort_inner','sort_attribute','option_tag_attribute_value','textCount']]\n",
    "sortname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/sort_model.sav\"\n",
    "sort_URL_name = sort_csv_df[[\"name_url\"]]\n",
    "p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "sort_model = pickle.load(open(sortname, 'rb'))\n",
    "sort_score = sort_model.predict(sort_X_test)\n",
    "target_names = ['Non-sort', 'Sort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e01c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./result/sort/sort_test__1.csv\")\n",
    "\n",
    "for (gender), group in data.groupby(['name_url']):\n",
    "     group.to_csv(f'{gender}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Get CSV files list from a folder\n",
    "path = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/sort/model_csv'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "for file in csv_files:\n",
    "    Search_csv_df = pd.read_csv(file)\n",
    "    search_URL_name = Search_csv_df[[\"name_url\"]]\n",
    "    nameCSV = (search_URL_name[\"name_url\"][0].split('/')[-1]).split('.')[0]\n",
    "    nameCSV = nameCSV+'.csv'\n",
    "    Search_X_test = Search_csv_df[[\"search_innertext\", \"search_attribute\", \"Number_of_search_word\",\"search_button_attribute_value\",\"is_button\"]]\n",
    "    searchname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/search_model.sav\"\n",
    "    target_names = ['Non-Search', 'Search']\n",
    "    data1_import = evaluation(Search_X_test,searchname,target_names,search_URL_name)\n",
    "    data2_import = pd.read_csv(Search_searchpath)   \n",
    "    data_merge = pd.concat([data1_import, data2_import],axis=1)\n",
    "    data_merge.to_csv(nameCSV, index = False)  # Export merged pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Search_X_test,searchname,target_names,search_URL_name):\n",
    "    p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "    searchname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/sort_model.sav\"\n",
    "    search_model = pickle.load(open(searchname, 'rb'))\n",
    "    y_score = search_model.predict(Search_X_test)\n",
    "    y_score_1 = search_model.predict_proba(Search_X_test)*100\n",
    "    #print(y_score_1)\n",
    "    for i in range(len(y_score_1)):\n",
    "        if y_score_1[i][1] >y_score_1[i][0]:\n",
    "            print([i],\"Positive Result\")\n",
    "            print(\"TRUE: \",y_score_1[i][1])\n",
    "            print(\"FALSE: \",y_score_1[i][0])\n",
    "            print(\"==========================\")\n",
    "        else:\n",
    "            print([i],\"Negative Result\")\n",
    "            print(\"TRUE: \",y_score_1[i][1])\n",
    "            print(\"FALSE: \",y_score_1[i][0])\n",
    "            print(\"==========================\")\n",
    "    df = pd.DataFrame(y_score_1) \n",
    "    return (df)\n",
    "data1_import = evaluation(sort_X_test,sortname,target_names,sort_URL_name)\n",
    "data2_import = pd.read_csv(sort_searchpath)   \n",
    "data_merge = pd.concat([data1_import, data2_import],axis=1)\n",
    "\n",
    "data_merge.to_csv(nameCSV, index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
