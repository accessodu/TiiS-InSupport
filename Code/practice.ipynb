{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c31e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "from testURL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cbd95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def pageListFunction(_url_):\n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    divPageList, navPageList,liPageList,ulPageList,spanPageList, sectionPageList, buttonPageList, \\\n",
    "    trPageList, footerPageList, aPageList, paginationPageList, bPageList \\\n",
    "    = soup.findAll('div',{\"data-attribute\":\"page\"}), soup.findAll('nav',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('li',{\"data-attribute\":\"page\"}), soup.findAll('ul',{\"data-attribute\":\"page\"}),\\\n",
    "    soup.findAll('span',{\"data-attribute\":\"page\"}), soup.findAll('section',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('button',{\"data-attribute\":\"page\"}), soup.findAll('tr',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('footer',{\"data-attribute\":\"page\"}), soup.findAll('a',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('pagination',{\"data-attribute\":\"page\"}), soup.findAll('b',{\"data-attribute\":\"page\"})\n",
    "    \n",
    "    try:\n",
    "        if divPageList != []:    \n",
    "            d_url_, d_NumOfButton, d_NumOfLinks, d_commonURL, d_NumberOfValues, d_page_attribute, d_NumOfPage, d_navType, d_PageListClass = pageList_Extract(soup, 'div',_url_)\n",
    "            return d_url_, d_NumOfButton, d_NumOfLinks, d_commonURL, d_NumberOfValues, d_page_attribute, d_NumOfPage, d_navType, d_PageListClass\n",
    "        \n",
    "        if navPageList != []:    \n",
    "            n_url_, n_NumOfButton, n_NumOfLinks, n_commonURL, n_NumberOfValues, n_page_attribute, n_NumOfPage, n_navType, n_PageListClass = pageList_Extract(soup, 'nav',_url_)\n",
    "            return n_url_, n_NumOfButton, n_NumOfLinks, n_commonURL, n_NumberOfValues, n_page_attribute, n_NumOfPage, n_navType, n_PageListClass\n",
    "        \n",
    "        if liPageList != []: \n",
    "            l_url_, l_NumOfButton, l_NumOfLinks, l_commonURL, l_NumberOfValues, l_page_attribute, l_NumOfPage, l_navType, l_PageListClass = pageList_Extract(soup, 'li',_url_)\n",
    "            return l_url_, l_NumOfButton, l_NumOfLinks, l_commonURL, l_NumberOfValues, l_page_attribute, l_NumOfPage, l_navType, l_PageListClass\n",
    "        \n",
    "        if ulPageList != []: \n",
    "            u_url_, u_NumOfButton, u_NumOfLinks, u_commonURL, u_NumberOfValues, u_page_attribute, u_NumOfPage, u_navType, u_PageListClass = pageList_Extract(soup, 'ul',_url_)\n",
    "            return u_url_, u_NumOfButton, u_NumOfLinks, u_commonURL, u_NumberOfValues, u_page_attribute, u_NumOfPage, u_navType, u_PageListClass\n",
    "        \n",
    "        if spanPageList != []:  \n",
    "            span_url_, span_NumOfButton, span_NumOfLinks, span_commonURL, span_NumberOfValues, span_page_attribute, span_NumOfPage, span_navType, span_PageListClass = pageList_Extract(soup, 'span',_url_)\n",
    "            return span_url_, span_NumOfButton, span_NumOfLinks, span_commonURL, span_NumberOfValues, span_page_attribute, span_NumOfPage, span_navType, span_PageListClass\n",
    "        \n",
    "        if sectionPageList != []: \n",
    "            sec_url_, sec_NumOfButton, sec_NumOfLinks, sec_commonURL, sec_NumberOfValues, sec_page_attribute, sec_NumOfPage, sec_navType, sec_PageListClass = pageList_Extract(soup, 'section',_url_) \n",
    "            return sec_url_, sec_NumOfButton, sec_NumOfLinks, sec_commonURL, sec_NumberOfValues, sec_page_attribute, sec_NumOfPage, sec_navType, sec_PageListClass \n",
    "        \n",
    "        if buttonPageList != []: \n",
    "            btn_url_, btn_NumOfButton, btn_NumOfLinks, btn_commonURL, btn_NumberOfValues, btn_page_attribute, btn_NumOfPage, btn_navType, btn_PageListClass = pageList_Extract(soup, 'button',_url_) \n",
    "            return btn_url_, btn_NumOfButton, btn_NumOfLinks, btn_commonURL, btn_NumberOfValues, btn_page_attribute, btn_NumOfPage, btn_navType, btn_PageListClass\n",
    "        \n",
    "        if trPageList != []: \n",
    "            tr_url_, tr_NumOfButton, tr_NumOfLinks, tr_commonURL, tr_NumberOfValues, tr_page_attribute, tr_NumOfPage, tr_navType, tr_PageListClass = pageList_Extract(soup, 'tr',_url_) \n",
    "            return tr_url_, tr_NumOfButton, tr_NumOfLinks, tr_commonURL, tr_NumberOfValues, tr_page_attribute, tr_NumOfPage, tr_navType, tr_PageListClass\n",
    "        \n",
    "        if footerPageList != []: \n",
    "            ft_url_, ft_NumOfButton, ft_NumOfLinks, ft_commonURL, ft_NumberOfValues, ft_page_attribute, ft_NumOfPage, ft_navType, ft_PageListClass = pageList_Extract(soup, 'footer',_url_) \n",
    "            return ft_url_, ft_NumOfButton, ft_NumOfLinks, ft_commonURL, ft_NumberOfValues, ft_page_attribute, ft_NumOfPage, ft_navType, ft_PageListClass \n",
    "        \n",
    "        if aPageList != []: \n",
    "            a_url_, a_NumOfButton, a_NumOfLinks, a_commonURL, a_NumberOfValues, a_page_attribute, a_NumOfPage, a_navType, a_PageListClass = pageList_Extract(soup, 'a',_url_) \n",
    "            return a_url_, a_NumOfButton, a_NumOfLinks, a_commonURL, a_NumberOfValues, a_page_attribute, a_NumOfPage, a_navType, a_PageListClass\n",
    "        \n",
    "        if paginationPageList != []: \n",
    "            pg_url_, pg_NumOfButton, pg_NumOfLinks, pg_commonURL, pg_NumberOfValues, pg_page_attribute, pg_NumOfPage, pg_navType, pg_PageListClass = pageList_Extract(soup, 'pagination',_url_) \n",
    "            return pg_url_, pg_NumOfButton, pg_NumOfLinks, pg_commonURL, pg_NumberOfValues, pg_page_attribute, pg_NumOfPage, pg_navType, pg_PageListClass\n",
    "        \n",
    "        if bPageList != []: \n",
    "            b_url_, b_NumOfButton, b_NumOfLinks, b_commonURL,  b_NumberOfValues, b_page_attribute, b_NumOfPage, b_navType, b_PageListClass = pageList_Extract(soup, 'b',_url_)  \n",
    "            return  b_url_, b_NumOfButton, b_NumOfLinks, b_commonURL,  b_NumberOfValues, b_page_attribute, b_NumOfPage, b_navType, b_PageListClass\n",
    "        else:\n",
    "            return _url_,\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"1\"\n",
    "    except:\n",
    "        pass\n",
    "def search(myDict, search1):\n",
    "    search.a=[]\n",
    "    for key, value in myDict.items():\n",
    "        if search1 in value:\n",
    "            search.a.append(key)\n",
    "    return len(search.a)\n",
    "\n",
    "\n",
    "def pageList_Extract(soup, tag,_url_):  \n",
    "    pageClass, NumOfPage, pageListAttribute, is_page, NumOfButton, NumOfLinks, NumberOfValues, outsideURL, insideURL, commonURL, \\\n",
    "    navType= [] ,[], [],[], [], [], [], [], [], [], []\n",
    "    count, btn, valueCounter = 0, 0, 0\n",
    "    print(\"Tag: \", tag)\n",
    "    for ele in soup.findAll(tag):\n",
    "        try:\n",
    "            #if \"data-attribute\" in list(ele.attrs.keys()) and \"page\" in list(ele.attrs.values()):\n",
    "                #=======================Common url=======================\n",
    "                insideURL, outsideURL = [], []\n",
    "                for link in ele.find_all('a'):\n",
    "                    insideURL.append(link.get('href'))\n",
    "                for link in soup.find_all('a'):\n",
    "                    outsideURL.append(link.get('href'))\n",
    "                def compare(list1,list2):\n",
    "                    ln= []\n",
    "                    for i in list1:\n",
    "                        if i  in list2:\n",
    "                           ln.append(i)\n",
    "                    return ln\n",
    "                s = -len(set(compare(insideURL,outsideURL)))+len(outsideURL)\n",
    "                commonURL.append(s)\n",
    "                print(\"[\",count,\"]\", len(s))\n",
    "                count+=1\n",
    "        except:\n",
    "                NumOfPage.append(0)\n",
    "                navType.append(0)\n",
    "                pass\n",
    "    \n",
    "    name_url = len(pageClass)*[_url_]\n",
    "\n",
    "    if (commonURL ==[] or commonURL is None):\n",
    "        commonURL = [0] \n",
    "\n",
    "    #print((navType), (name_url), (NumOfButton), (NumOfLinks), (commonURL), (is_page), (pageClass), (NumOfPage))\n",
    "    print(\"Final:\",commonURL)\n",
    "for i in range(0,1):\n",
    "    pageListFunction(turl[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1ad8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mdjavedulferdous/Documents/Dataset/New Dataset\n"
     ]
    }
   ],
   "source": [
    "cd \"/Users/mdjavedulferdous/Documents/Dataset/New Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d21a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "from allURL import *\n",
    "\n",
    "def search(myDict, search1):\n",
    "    search.a=[]\n",
    "    for key, value in myDict.items():\n",
    "        if search1 in value:\n",
    "            search.a.append(key)\n",
    "    return len(search.a)\n",
    "\n",
    "\n",
    "def pageList_Extract(soup, tag,_url_):  \n",
    "    pageClass, NumOfPage, pageListAttribute, is_page, NumOfButton, NumOfLinks, NumberOfValues, outsideURL, insideURL, commonURL, \\\n",
    "    navType= [] ,[], [],[], [], [], [], [], [], [], []\n",
    "    count, btn, valueCounter = 0, 0, 0\n",
    "    print(\"Tag: \", tag)\n",
    "    for ele in soup.findAll(tag):\n",
    "        try:\n",
    "            if \"data-attribute\" in list(ele.attrs.keys()) and \"page\" in list(ele.attrs.values()):\n",
    "                #print(ele)\n",
    "                nText = ele.text\n",
    "                #=======================Page Class======================= \n",
    "                pageClass.append(1)\n",
    "                #=======================Page Name======================= \n",
    "                is_present = bool(re.search('page', str(ele)) or re.search('show', str(ele)))\n",
    "                if(is_present == True):\n",
    "                    is_page.append(1)\n",
    "                else:\n",
    "                    is_page.append(0)\n",
    "                #====================Number of links==================== \n",
    "                for link in ele.find_all('a'):\n",
    "                    count += 1\n",
    "                NumOfLinks.append(count)\n",
    "                #====================Number of Button==================== \n",
    "                for btnlink in ele.find_all('button'):\n",
    "                    btn += 1\n",
    "                NumOfButton.append(btn)\n",
    "                #=======================Common url=======================\n",
    "                insideURL, outsideURL = [], []\n",
    "                for link in ele.find_all('a'):\n",
    "                    insideURL.append(link.get('href'))\n",
    "                for link in soup.find_all('a'):\n",
    "                    outsideURL.append(link.get('href'))\n",
    "                def compare(list1,list2):\n",
    "                    ln= []\n",
    "                    for i in list1:\n",
    "                        if i  in list2:\n",
    "                           ln.append(i)\n",
    "                    return ln\n",
    "                s = -len(set(compare(insideURL,outsideURL)))+len(outsideURL)\n",
    "                commonURL.append(s)\n",
    "                \n",
    "                #=====================Number of values=====================\n",
    "                for link in ele.find_all('a'):\n",
    "                    if (link.text).isdigit()==True:\n",
    "                        valueCounter += 1\n",
    "                NumberOfValues.append(valueCounter)\n",
    "                #print(valueCounter)\n",
    "                \n",
    "                #=====================Number of pages=====================\n",
    "                temp1 = re.findall(r'\\d+', ele.text) \n",
    "                res2 = list(map(int, temp1))\n",
    "                if(len(res2)==1):\n",
    "                    if res2==[0] or res2==[]:\n",
    "                        NumOfPage.append(1)\n",
    "                    else:\n",
    "                        NumOfPage.append(str(res2[0])[0:2])\n",
    "                else:\n",
    "                    if res2==[0] or res2==[]:\n",
    "                        NumOfPage.append(1)\n",
    "                    else:\n",
    "                        NumOfPage.append(str(res2[-1])[0:2])\n",
    "                #print(res2[-1])\n",
    "                #=====================Navigation type=====================\n",
    "                nav = ele.find('button')\n",
    "                alink = ele.find('a')\n",
    "                if (bool(nav)) == True:\n",
    "                    if(bool(alink)) == True and (bool(nav)) == True:\n",
    "                        navType.append(3)\n",
    "                    else:\n",
    "                        navType.append(1)\n",
    "                elif(bool(alink)) == True:\n",
    "                    navType.append(2)\n",
    "                else:\n",
    "                    navType.append(0)\n",
    "            else:\n",
    "                pageClass.append(0)\n",
    "                is_page.append(0)\n",
    "                NumOfButton.append(0)\n",
    "                NumOfLinks.append(0)\n",
    "                commonURL.append(0)\n",
    "                NumberOfValues.append(0)\n",
    "                NumOfPage.append(0)\n",
    "                navType.append(0)\n",
    "        except:\n",
    "                NumOfPage.append(0)\n",
    "                navType.append(0)\n",
    "                pass\n",
    "    \n",
    "    name_url = len(pageClass)*[_url_]\n",
    "    if (NumOfLinks ==[] or NumOfLinks is None):\n",
    "        NumOfLinks = [0]\n",
    "    if (NumOfButton ==[] or NumOfButton is None):\n",
    "        NumOfButton = [0] \n",
    "    if (commonURL ==[] or commonURL is None):\n",
    "        commonURL = [0] \n",
    "    if (pageClass == [] or pageClass is None):\n",
    "        pageClass = [1]\n",
    "    if (is_page == [] or is_page is None):\n",
    "        is_page = [0]    \n",
    "    if (NumOfPage == [] or NumOfPage is None):\n",
    "        NumOfPage = [0]\n",
    "    if (NumberOfValues == [] or NumberOfValues is None):\n",
    "        NumberOfValues = [0]\n",
    "    if (navType == [] or navType is None):\n",
    "        navType = [0]\n",
    "    #print(len(navType), len(name_url), len(NumOfButton), len(NumOfLinks), len(commonURL), len(is_page), len(pageClass), len(NumOfPage))     \n",
    "    return name_url, NumOfButton, NumOfLinks, commonURL, NumberOfValues, is_page, NumOfPage, navType, pageClass \n",
    "\n",
    "\n",
    "\n",
    "def get_class_data(searchQ) :\n",
    "        start_time= time.time()\n",
    "        name_url, NumOfButton, NumOfLinks, commonURL,NumberOfValues, is_page, NumOfPage, navType, pageClass = pageListFunction(searchQ)\n",
    "        #checkBoxList = str(checkBoxList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #insideList = str(insideList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #filterClass = str(filterClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in NumOfButton:\n",
    "            NumOfButton = i\n",
    "            temp.append([NumOfButton])        \n",
    "        \n",
    "        t_NumOfLinks= []\n",
    "        for m in NumOfLinks:\n",
    "            t_NumOfLinks.append(m)\n",
    "        NumOfLinks_arr2d = np.matrix(temp)\n",
    "        NumOfLinks_to_add = np.array(t_NumOfLinks)\n",
    "        output_NumOfLinks = np.column_stack((NumOfLinks_arr2d, NumOfLinks_to_add))\n",
    "        f_NumOfLinks = output_NumOfLinks.tolist()\n",
    "        \n",
    "        t_commonURL = []\n",
    "        for m in commonURL:\n",
    "            t_commonURL.append(m)\n",
    "        commonURL_arr2d = np.matrix(f_NumOfLinks)\n",
    "        commonURL_to_add = np.array(t_commonURL)\n",
    "        output_commonURL = np.column_stack((commonURL_arr2d, commonURL_to_add))\n",
    "        f_commonURL = output_commonURL.tolist()\n",
    "        \n",
    "        t_is_Page = []\n",
    "        for m in is_page:\n",
    "            t_is_Page.append(m)\n",
    "        is_Page_arr2d = np.matrix(f_commonURL)\n",
    "        is_Page_to_add = np.array(t_is_Page)\n",
    "        output_is_Page = np.column_stack((is_Page_arr2d, is_Page_to_add))\n",
    "        f_is_Page = output_is_Page.tolist()\n",
    "        \n",
    "        t_NumOfPage = []\n",
    "        for m in NumOfPage:\n",
    "            t_NumOfPage.append(m)\n",
    "        NumOfPage_arr2d = np.matrix(f_is_Page)\n",
    "        NumOfPage_to_add = np.array(t_NumOfPage)\n",
    "        output_NumOfPage = np.column_stack((NumOfPage_arr2d, NumOfPage_to_add))\n",
    "        f_NumOfPage = output_NumOfPage.tolist()\n",
    "        \n",
    "        t_NumberOfValues = []\n",
    "        for m in NumberOfValues:\n",
    "            t_NumberOfValues.append(m)\n",
    "        NumberOfValues_arr2d = np.matrix(f_NumOfPage)\n",
    "        NumberOfValues_to_add = np.array(t_NumberOfValues)\n",
    "        output_NumberOfValues = np.column_stack((NumberOfValues_arr2d, NumberOfValues_to_add))\n",
    "        f_NumberOfValues = output_NumberOfValues.tolist()\n",
    "        \n",
    "        t_navType = []\n",
    "        for m in navType:\n",
    "            t_navType.append(m)\n",
    "        navType_arr2d = np.matrix(f_NumberOfValues)\n",
    "        navType_to_add = np.array(t_navType)\n",
    "        output_navType = np.column_stack((navType_arr2d, navType_to_add))\n",
    "        f_navType = output_navType.tolist()\n",
    "        \n",
    "        t_pageClass = []\n",
    "        for m in pageClass:\n",
    "            t_pageClass.append(m)\n",
    "        pageClass_arr2d = np.matrix(f_navType)\n",
    "        pageClass_to_add = np.array(t_pageClass)\n",
    "        output_pageClass = np.column_stack((pageClass_arr2d, pageClass_to_add))\n",
    "        f_pageClass = output_pageClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_pageClass)\n",
    "        column_name = np.array(name_url)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        hours, rem = divmod(end-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"\\nTime takes: {:0>2}:{:0>2}:{:05.2f} Seconds\\n\".format(int(hours),int(minutes),seconds))\n",
    "        return f_name\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"NumOfButton\", \"NumOfLinks\", \"commonURL\",\"is_page\", \"NumOfPage\", \"NumberOfValues\",\"navType\",\"pageClass\", \"name_url\"]\n",
    "    save_path = 'test/'\n",
    "    file_name = \"pageList_test_2.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'test/'\n",
    "    file_name = \"pageList_test_2.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"rows!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "\n",
    "    for i in range(0,209):\n",
    "            print(write_CSV(get_class_data(urllist[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2acfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l1', solver='liblinear',tol=1e-6,warm_start=True, intercept_scaling=10000.)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "_classifier_ = []\n",
    "_classifier_.append(lr)\n",
    "#_classifier_.append(mlp)\n",
    "#_classifier_.append(svc)\n",
    "\n",
    "\n",
    "p_class_0,p_class_1 = [], []\n",
    "def model_evaluate(model, x_train, y_train, X_test,y_test):\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    # save the model to disk\n",
    "    filename = '/Users/mdjavedulferdous/Desktop/TiiS/Code/page_model_2.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    model_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, model_pred))\n",
    "    print(\"Cross validation score: {:.1f}\".format(model_selection.cross_val_score(model, x_train, y_train).mean()*100))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, model_pred).ravel()\n",
    "    print(\"True negative: %s \\nFalse positive: %s \\nFalse negative: %s \\nTrue positive: %s\\n\\n\" % (tn, fp, fn, tp))\n",
    "    cDF = pd.DataFrame(model_pred)\n",
    "    y_test = np.asarray(y_test)\n",
    "    misclassified = [i for i in range(len(model_pred)) if model_pred[i] != y_test[i]]\n",
    "    print(\"Misclassified index: \", misclassified)\n",
    "    precision = precision_score(y_test, model_pred, average=None)\n",
    "    p_class_0.append(precision[0])\n",
    "    p_class_1.append(precision[1])\n",
    "    recall = recall_score(y_test, model_pred, average=None)\n",
    "    return p_class_0,p_class_1\n",
    "    \n",
    "def process(model):\n",
    "    csv_df = pd.read_csv(\"test/pageList_test_2.csv\")\n",
    "    filtered_one = csv_df[csv_df['pageClass'] != 0] \n",
    "    filtered_zero = csv_df[csv_df['pageClass'] == 0] \n",
    "    f_o = filtered_zero.sample(n=209,replace=False)\n",
    "    z = pd.concat([filtered_one, f_o], axis=0)\n",
    "    z  = z.reset_index(drop=True)\n",
    "    x_2 = z[['NumOfButton','NumOfLinks','commonURL','is_page','NumOfPage','NumberOfValues','navType']]\n",
    "    y_2 = z[[\"pageClass\"]]\n",
    "        \n",
    "    fivefold = [\n",
    "             (np.r_[1:168,209:335,376:418], np.r_[168:209,335:376]),\n",
    "             (np.r_[1:83,124:239, 280:418], np.r_[83:124, 239:280]),\n",
    "             (np.r_[1:124, 165:377], np.r_[124:165,377:418]),\n",
    "             (np.r_[1:168, 251:418], np.r_[168:251]),\n",
    "             (np.r_[1:100,142:209,250:418], np.r_[100:142, 209:250])\n",
    "    ]\n",
    "    print(model)\n",
    "    fold = 1\n",
    "    for train_index, test_index in fivefold:\n",
    "        \n",
    "        print(\"Fold: \",fold)\n",
    "        print(\"==================================================================\")\n",
    "        X_train, X_test, y_train, y_test = x_2.iloc[train_index], x_2.iloc[test_index], y_2.iloc[train_index], y_2.iloc[test_index]\n",
    "        print(len(X_train))\n",
    "        print(len(y_train))\n",
    "        print(len(X_test))\n",
    "        print(len(y_test))\n",
    "        print(\"==================================================================\")\n",
    "        model_evaluate(model, X_train, y_train, X_test,y_test)\n",
    "        print(\"==================================================================\")\n",
    "        fold +=1\n",
    "for i in _classifier_:\n",
    "    process(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759317d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time takes: 00:00:00.14 Seconds\n",
      "\n",
      "[ 347 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.96 Seconds\n",
      "\n",
      "[ 1980 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 2988 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.45 Seconds\n",
      "\n",
      "[ 5475 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.44 Seconds\n",
      "\n",
      "[ 7867 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.38 Seconds\n",
      "\n",
      "[ 7868 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.73 Seconds\n",
      "\n",
      "[ 10019 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.51 Seconds\n",
      "\n",
      "[ 12334 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.08 Seconds\n",
      "\n",
      "[ 12806 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.24 Seconds\n",
      "\n",
      "[ 13341 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.24 Seconds\n",
      "\n",
      "[ 14517 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.39 Seconds\n",
      "\n",
      "[ 14667 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 14933 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.34 Seconds\n",
      "\n",
      "[ 15785 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.51 Seconds\n",
      "\n",
      "[ 16839 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.56 Seconds\n",
      "\n",
      "[ 19839 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.31 Seconds\n",
      "\n",
      "[ 20744 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.59 Seconds\n",
      "\n",
      "[ 22403 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.40 Seconds\n",
      "\n",
      "[ 23712 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:02.05 Seconds\n",
      "\n",
      "[ 28837 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 29993 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.11 Seconds\n",
      "\n",
      "[ 31521 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.04 Seconds\n",
      "\n",
      "[ 34491 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.79 Seconds\n",
      "\n",
      "[ 36491 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.27 Seconds\n",
      "\n",
      "[ 37308 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 37315 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 38337 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 38350 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.16 Seconds\n",
      "\n",
      "[ 39328 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 40320 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.76 Seconds\n",
      "\n",
      "[ 41258 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.65 Seconds\n",
      "\n",
      "[ 41645 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 41696 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 41714 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.79 Seconds\n",
      "\n",
      "[ 43839 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.22 Seconds\n",
      "\n",
      "[ 44605 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.40 Seconds\n",
      "\n",
      "[ 45106 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 45454 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.22 Seconds\n",
      "\n",
      "[ 46113 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.42 Seconds\n",
      "\n",
      "[ 46867 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.91 Seconds\n",
      "\n",
      "[ 48411 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.21 Seconds\n",
      "\n",
      "[ 49004 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 49008 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.45 Seconds\n",
      "\n",
      "[ 50317 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.07 Seconds\n",
      "\n",
      "[ 50321 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 50970 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.11 Seconds\n",
      "\n",
      "[ 51124 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 51860 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 53143 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.15 Seconds\n",
      "\n",
      "[ 53593 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 53844 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.11 Seconds\n",
      "\n",
      "[ 53956 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.06 Seconds\n",
      "\n",
      "[ 53976 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.43 Seconds\n",
      "\n",
      "[ 54494 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 54754 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.71 Seconds\n",
      "\n",
      "[ 55208 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.41 Seconds\n",
      "\n",
      "[ 56236 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.49 Seconds\n",
      "\n",
      "[ 56255 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.08 Seconds\n",
      "\n",
      "[ 56384 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.41 Seconds\n",
      "\n",
      "[ 56983 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.91 Seconds\n",
      "\n",
      "[ 59256 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.47 Seconds\n",
      "\n",
      "[ 59273 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.17 Seconds\n",
      "\n",
      "[ 59447 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.83 Seconds\n",
      "\n",
      "[ 60574 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.59 Seconds\n",
      "\n",
      "[ 60575 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.25 Seconds\n",
      "\n",
      "[ 60978 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.09 Seconds\n",
      "\n",
      "[ 61163 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.33 Seconds\n",
      "\n",
      "[ 61701 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.42 Seconds\n",
      "\n",
      "[ 61767 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.65 Seconds\n",
      "\n",
      "[ 63341 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.11 Seconds\n",
      "\n",
      "[ 63645 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.11 Seconds\n",
      "\n",
      "[ 63901 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.10 Seconds\n",
      "\n",
      "[ 64163 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 64183 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.53 Seconds\n",
      "\n",
      "[ 64184 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 65062 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 67153 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.24 Seconds\n",
      "\n",
      "[ 67164 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.11 Seconds\n",
      "\n",
      "[ 67534 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.47 Seconds\n",
      "\n",
      "[ 67586 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.45 Seconds\n",
      "\n",
      "[ 68056 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.17 Seconds\n",
      "\n",
      "[ 68057 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.25 Seconds\n",
      "\n",
      "[ 69489 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.64 Seconds\n",
      "\n",
      "[ 71525 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.23 Seconds\n",
      "\n",
      "[ 81101 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.16 Seconds\n",
      "\n",
      "[ 81344 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 82246 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.09 Seconds\n",
      "\n",
      "[ 82273 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.77 Seconds\n",
      "\n",
      "[ 84889 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.17 Seconds\n",
      "\n",
      "[ 86028 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.32 Seconds\n",
      "\n",
      "[ 87470 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.66 Seconds\n",
      "\n",
      "[ 87471 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.14 Seconds\n",
      "\n",
      "[ 88059 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.14 Seconds\n",
      "\n",
      "[ 91918 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 92223 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.95 Seconds\n",
      "\n",
      "[ 95934 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.37 Seconds\n",
      "\n",
      "[ 96147 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 96685 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.54 Seconds\n",
      "\n",
      "[ 98097 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.48 Seconds\n",
      "\n",
      "[ 100171 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.38 Seconds\n",
      "\n",
      "[ 101308 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:02.34 Seconds\n",
      "\n",
      "[ 109246 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.98 Seconds\n",
      "\n",
      "[ 111202 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 111620 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 111621 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.72 Seconds\n",
      "\n",
      "[ 113466 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 113870 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 114484 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.31 Seconds\n",
      "\n",
      "[ 114983 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 115476 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.60 Seconds\n",
      "\n",
      "[ 115480 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.83 Seconds\n",
      "\n",
      "[ 116546 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.09 Seconds\n",
      "\n",
      "[ 121123 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.77 Seconds\n",
      "\n",
      "[ 121825 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.53 Seconds\n",
      "\n",
      "[ 123296 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.08 Seconds\n",
      "\n",
      "[ 123432 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.48 Seconds\n",
      "\n",
      "[ 125974 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 126906 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 127602 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.92 Seconds\n",
      "\n",
      "[ 131934 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.07 Seconds\n",
      "\n",
      "[ 131935 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.43 Seconds\n",
      "\n",
      "[ 133520 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 134233 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 134756 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.49 Seconds\n",
      "\n",
      "[ 136108 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 136109 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.08 Seconds\n",
      "\n",
      "[ 137599 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.31 Seconds\n",
      "\n",
      "[ 138867 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.57 Seconds\n",
      "\n",
      "[ 140245 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.82 Seconds\n",
      "\n",
      "[ 141001 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 142095 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.72 Seconds\n",
      "\n",
      "[ 143933 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 143934 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.17 Seconds\n",
      "\n",
      "[ 144239 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.50 Seconds\n",
      "\n",
      "[ 144257 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 144261 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.55 Seconds\n",
      "\n",
      "[ 146711 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.10 Seconds\n",
      "\n",
      "[ 146930 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.90 Seconds\n",
      "\n",
      "[ 148812 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.86 Seconds\n",
      "\n",
      "[ 151602 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.48 Seconds\n",
      "\n",
      "[ 151603 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.55 Seconds\n",
      "\n",
      "[ 153642 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 154257 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 155019 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 155661 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.21 Seconds\n",
      "\n",
      "[ 156791 ]. rows!\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time takes: 00:00:00.40 Seconds\n",
      "\n",
      "[ 157847 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.69 Seconds\n",
      "\n",
      "[ 161868 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.33 Seconds\n",
      "\n",
      "[ 162755 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.58 Seconds\n",
      "\n",
      "[ 163766 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.51 Seconds\n",
      "\n",
      "[ 163946 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 164122 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 164192 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.15 Seconds\n",
      "\n",
      "[ 164393 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.12 Seconds\n",
      "\n",
      "[ 164480 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.31 Seconds\n",
      "\n",
      "[ 165416 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 166394 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.54 Seconds\n",
      "\n",
      "[ 166750 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.77 Seconds\n",
      "\n",
      "[ 167579 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 167580 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.25 Seconds\n",
      "\n",
      "[ 168200 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.50 Seconds\n",
      "\n",
      "[ 170557 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.12 Seconds\n",
      "\n",
      "[ 170771 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.45 Seconds\n",
      "\n",
      "[ 170772 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.90 Seconds\n",
      "\n",
      "[ 171598 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 172141 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.32 Seconds\n",
      "\n",
      "[ 172728 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.37 Seconds\n",
      "\n",
      "[ 173394 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.20 Seconds\n",
      "\n",
      "[ 173909 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.21 Seconds\n",
      "\n",
      "[ 174542 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.16 Seconds\n",
      "\n",
      "[ 174588 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.13 Seconds\n",
      "\n",
      "[ 174596 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.20 Seconds\n",
      "\n",
      "[ 175139 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.80 Seconds\n",
      "\n",
      "[ 176624 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 178048 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 179173 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 179174 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 179490 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.75 Seconds\n",
      "\n",
      "[ 181241 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.07 Seconds\n",
      "\n",
      "[ 181494 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.67 Seconds\n",
      "\n",
      "[ 182336 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.33 Seconds\n",
      "\n",
      "[ 183760 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.22 Seconds\n",
      "\n",
      "[ 184344 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.08 Seconds\n",
      "\n",
      "[ 184389 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 184808 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.27 Seconds\n",
      "\n",
      "[ 184813 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 185669 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.20 Seconds\n",
      "\n",
      "[ 185670 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.51 Seconds\n",
      "\n",
      "[ 186571 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 186977 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 187606 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.25 Seconds\n",
      "\n",
      "[ 187612 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.22 Seconds\n",
      "\n",
      "[ 188218 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 189103 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.40 Seconds\n",
      "\n",
      "[ 189121 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.16 Seconds\n",
      "\n",
      "[ 189213 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.82 Seconds\n",
      "\n",
      "[ 192345 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 192409 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.18 Seconds\n",
      "\n",
      "[ 192810 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.08 Seconds\n",
      "\n",
      "[ 192811 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.21 Seconds\n",
      "\n",
      "[ 193272 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.13 Seconds\n",
      "\n",
      "[ 193767 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 194637 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.14 Seconds\n",
      "\n",
      "[ 194638 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.00 Seconds\n",
      "\n",
      "[ 196933 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.92 Seconds\n",
      "\n",
      "[ 200518 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.59 Seconds\n",
      "\n",
      "[ 202166 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.44 Seconds\n",
      "\n",
      "[ 202184 ]. rows!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.19 Seconds\n",
      "\n",
      "[ 207270 ]. rows!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from init import *\n",
    "from allURL import *\n",
    "\n",
    "def filterFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    divFilter, ulFilter, liFilter, formFilter, sectionFilter, fieldsetFilter, dtFilter,\\\n",
    "    buttonFilter,articleFilter,dlFilter,desktopfacetFilter = \\\n",
    "    soup.findAll('div',{\"data-attribute\":\"filter\"}),soup.findAll('ul',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('li',{\"data-attribute\":\"filter\"}), soup.findAll('form',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('section',{\"data-attribute\":\"filter\"}), soup.findAll('fieldset',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('dt',{\"data-attribute\":\"filter\"}),soup.findAll('button',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('article',{\"data-attribute\":\"filter\"}), soup.findAll('dl',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('desktop-facet',{\"data-attribute\":\"filter\"})\n",
    "    try:\n",
    "        if divFilter != []:    \n",
    "            div_name_url, div_checkBoxList, div_NumberOfLink, div_NumberOfInput, div_URL_List, div_button_List, div_filterClass = filter_Extract(soup, 'div',_url_)\n",
    "            return div_name_url, div_checkBoxList, div_NumberOfLink, div_NumberOfInput, div_URL_List, div_button_List, div_filterClass\n",
    "        if liFilter != []:    \n",
    "            li_name_url,  li_checkBoxList,  li_NumberOfLink,  li_NumberOfInput,  li_URL_List, li_button_List, li_filterClass = filter_Extract(soup, 'li',_url_)\n",
    "            return li_name_url,  li_checkBoxList,  li_NumberOfLink,  li_NumberOfInput, li_URL_List, li_button_List, li_filterClass\n",
    "        if buttonFilter != []:    \n",
    "            button_name_url, button_checkBoxList, button_NumberOfLink, button_NumberOfInput, button_URL_List, button_button_List, button_filterClass = filter_Extract(soup, 'button',_url_)\n",
    "            return button_name_url, button_checkBoxList, button_NumberOfLink, button_NumberOfInput, button_URL_List, button_button_List, button_filterClass\n",
    "        if dlFilter != []:    \n",
    "            dl_name_url, dl_checkBoxList, dl_NumberOfLink, dl_NumberOfInput, dl_URL_List, dl_button_List, dl_filterClass = filter_Extract(soup, 'dl',_url_)\n",
    "            return dl_name_url, dl_checkBoxList, dl_NumberOfLink, dl_NumberOfInput, dl_URL_List, dl_button_List, dl_filterClass \n",
    "        if desktopfacetFilter != []:    \n",
    "            df_name_url, df_checkBoxList, df_NumberOfLink, df_NumberOfInput, df_URL_List, df_button_List, df_filterClass = filter_Extract(soup, 'desktop-facet',_url_)\n",
    "            return df_name_url, df_checkBoxList, df_NumberOfLink, df_NumberOfInput, df_URL_List, df_button_List, df_filterClass\n",
    "        if articleFilter != []:    \n",
    "            art_name_url, art_checkBoxList, art_NumberOfLink, art_NumberOfInput, art_URL_List, art_button_List, art_filterClass = filter_Extract(soup, 'article',_url_)\n",
    "            return art_name_url, art_checkBoxList, art_NumberOfLink, art_NumberOfInput, art_URL_List, art_button_List, art_filterClass\n",
    "        if dtFilter != []:    \n",
    "            dt_name_url, dt_checkBoxList, dt_NumberOfLink, dt_NumberOfInput, dt_URL_List, dt_button_List, dt_filterClass = filter_Extract(soup, 'dt',_url_)\n",
    "            return dt_name_url, dt_checkBoxList, dt_NumberOfLink, dt_NumberOfInput, dt_URL_List, dt_button_List, dt_filterClass \n",
    "        if fieldsetFilter != []:    \n",
    "            f_name_url, f_checkBoxList, f_NumberOfLink, f_NumberOfInput, f_URL_List, f_button_List, f_filterClass = filter_Extract(soup, 'fieldset',_url_)\n",
    "            return f_name_url, f_checkBoxList, f_NumberOfLink, f_NumberOfInput, f_URL_List, f_button_List, f_filterClass\n",
    "        if sectionFilter != []:    \n",
    "            s_name_url, s_checkBoxList, s_NumberOfLink, s_NumberOfInput, s_URL_List, s_button_List, s_filterClass = filter_Extract(soup, 'section',_url_)\n",
    "            return s_name_url, s_checkBoxList, s_NumberOfLink, s_NumberOfInput, s_URL_List, s_button_List, s_filterClass\n",
    "        if formFilter != []:    \n",
    "            form_name_url, form_checkBoxList, form_NumberOfLink, form_NumberOfInput, form_URL_List, form_button_List, form_filterClass = filter_Extract(soup, 'form',_url_)\n",
    "            return form_name_url, form_checkBoxList, form_NumberOfLink, form_NumberOfInput, form_URL_List, form_button_List, form_filterClass\n",
    "        if ulFilter != []:    \n",
    "            ul_name_url, ul_checkBoxList, ul_NumberOfLink, ul_NumberOfInput, ul_URL_List, ul_button_List, ul_filterClass = filter_Extract(soup, 'ul',_url_)\n",
    "            return ul_name_url, ul_checkBoxList, ul_NumberOfLink, ul_NumberOfInput, ul_URL_List, ul_button_List, ul_filterClass\n",
    "        else:\n",
    "            return _url_,\"0\",\"0\",\"0\",\"0\",\"0\",\"1\"\n",
    "    except:\n",
    "        pass\n",
    "def filter_Extract(soup, tag,_url_):\n",
    "    fCount  = 0\n",
    "    filterClass, checkBoxList,insideList,outerList, NumberOfFilter, NumberOfLink, temp2,\\\n",
    "    NumberOfInput, URL_List, button_List = [], [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    for ele in soup.findAll(tag):\n",
    "                if \"data-attribute\" in list(ele.attrs.keys()) and \"filter\" in list(ele.attrs.values()):\n",
    "                        #======================= filterClass =======================\n",
    "                        filterClass.append(1)\n",
    "                        fCount +=1\n",
    "                        ch1 = 0\n",
    "                       \n",
    "                        #======================= Sub-Category ======================= \n",
    "                        child = 0\n",
    "                        for scat in ele.findAll('label'):\n",
    "                            child +=1\n",
    "                            #print(scat.text)\n",
    "                        insideList.append(child)\n",
    "                        #========================= CheckBox =========================             \n",
    "                        for chk in ele.findAll('input', {\"type\": \"checkbox\"}):\n",
    "                            pass\n",
    "                            ch1 += 1\n",
    "                        if ch1 !=0 and ch1 !=1:\n",
    "                            pass\n",
    "                            #print(ch1)\n",
    "                            checkBoxList.append(1)\n",
    "                        elif ch1 is None:\n",
    "                            pass\n",
    "                            #print(\"Empty\")\n",
    "                        else:\n",
    "                            checkBoxList.append(0)\n",
    "                      \n",
    "                        #=================== Number of link used =================== \n",
    "                        valueCounter =0\n",
    "                        for link in ele.findAll('a'):\n",
    "                            valueCounter += 1\n",
    "                        NumberOfLink.append(valueCounter)\n",
    "                        #=================== Number of inputbox =================== \n",
    "                        inputCounter = 0\n",
    "                        for link in ele.findAll('input'):\n",
    "                            inputCounter += 1\n",
    "                        NumberOfInput.append(inputCounter)\n",
    "                        #=================== Number of URL List =================== \n",
    "                        linkCount = 0\n",
    "                        for alink in ele.findAll('a', href=True):\n",
    "                            linkCount += 1\n",
    "                        URL_List.append(1)\n",
    "                        #=================== Number of button List =================== \n",
    "                        buttonCount = 0\n",
    "                        for btn in ele.findAll('button'):\n",
    "                            buttonCount += 1\n",
    "                        if buttonCount!=1:\n",
    "                            button_List.append(1)\n",
    "                        else:\n",
    "                            button_List.append(0)\n",
    "                else:\n",
    "                    filterClass.append(0)\n",
    "                    checkBoxList.append(0)  \n",
    "                    NumberOfLink.append(0)\n",
    "                    NumberOfInput.append(0)\n",
    "                    URL_List.append(0)\n",
    "                    button_List.append(0)\n",
    "\n",
    "    name_url = len(filterClass)*[_url_]\n",
    "    if (NumberOfLink ==[] or NumberOfLink is None):\n",
    "        NumberOfLink = [0]\n",
    "    if (NumberOfInput ==[] or NumberOfInput is None):\n",
    "        NumberOfInput = [0] \n",
    "    if (checkBoxList ==[] or checkBoxList is None):\n",
    "        checkBoxList = [0]\n",
    "    if (URL_List ==[] or URL_List is None):\n",
    "        URL_List = [0]\n",
    "    if (button_List ==[] or button_List is None):\n",
    "        button_List = [0]\n",
    "    if (filterClass == [] or filterClass is None):\n",
    "        filterClass = [1]\n",
    "    #print(len(filterClass))\n",
    "    #print(len(checkBoxList))\n",
    "    #print(len(NumberOfLink))\n",
    "    #print(len(NumberOfInput))\n",
    "    #print(len(URL_List))\n",
    "    #print(len(button_List))\n",
    "    return name_url, checkBoxList, NumberOfLink, NumberOfInput, URL_List, button_List, filterClass\n",
    "def get_class_data(searchQ) :\n",
    "        start_time= time.time()\n",
    "        name_url, checkBoxList, NumberOfLink, NumberOfInput, URL_List, button_List, filterClass = filterFunc(searchQ)\n",
    "        #checkBoxList = str(checkBoxList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #insideList = str(insideList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #filterClass = str(filterClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in checkBoxList:\n",
    "            checkBoxList = i\n",
    "            temp.append([checkBoxList])        \n",
    "        \n",
    "        t_NumberOfLink= []\n",
    "        for m in NumberOfLink:\n",
    "            t_NumberOfLink.append(m)\n",
    "        NumOfLinks_arr2d = np.matrix(temp)\n",
    "        NumOfLinks_to_add = np.array(t_NumberOfLink)\n",
    "        output_NumOfLinks = np.column_stack((NumOfLinks_arr2d, NumOfLinks_to_add))\n",
    "        f_NumOfLinks = output_NumOfLinks.tolist()\n",
    "        \n",
    "        t_NumberOfInput = []\n",
    "        for m in NumberOfInput:\n",
    "            t_NumberOfInput.append(m)\n",
    "        NumberOfInput_arr2d = np.matrix(f_NumOfLinks)\n",
    "        NumberOfInput_to_add = np.array(t_NumberOfInput)\n",
    "        output_NumberOfInput = np.column_stack((NumberOfInput_arr2d, NumberOfInput_to_add))\n",
    "        f_NumberOfInput = output_NumberOfInput.tolist()\n",
    "        \n",
    "        t_URL_List = []\n",
    "        for m in URL_List:\n",
    "            t_URL_List.append(m)\n",
    "        URL_List_arr2d = np.matrix(f_NumberOfInput)\n",
    "        URL_List_to_add = np.array(t_URL_List)\n",
    "        output_URL_List = np.column_stack((URL_List_arr2d, URL_List_to_add))\n",
    "        f_URL_List= output_URL_List.tolist()\n",
    "        \n",
    "        t_button_List = []\n",
    "        for m in button_List:\n",
    "            t_button_List.append(m)\n",
    "        button_List_arr2d = np.matrix(f_URL_List)\n",
    "        button_List_to_add = np.array(t_button_List)\n",
    "        output_button_List = np.column_stack((button_List_arr2d, button_List_to_add))\n",
    "        f_button_List= output_button_List.tolist()\n",
    "        \n",
    "        t_filterClass = []\n",
    "        for m in filterClass:\n",
    "            t_filterClass.append(m)\n",
    "        filterClass_arr2d = np.matrix(f_button_List)\n",
    "        filterClass_to_add = np.array(t_filterClass)\n",
    "        output_filterClass = np.column_stack((filterClass_arr2d, filterClass_to_add))\n",
    "        f_filterClass = output_filterClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_filterClass)\n",
    "        column_name = np.array(name_url)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        hours, rem = divmod(end-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"\\nTime takes: {:0>2}:{:0>2}:{:05.2f} Seconds\\n\".format(int(hours),int(minutes),seconds))\n",
    "        return f_name\n",
    "    \n",
    "def write_header():\n",
    "    list_of_header = [\"checkBoxList\", \"NumberOfLink\",\"NumberOfInput\", \"URL_List\", \"button_List\",\"filterClass\", \"name_url\"]\n",
    "    save_path = 'test/'\n",
    "    file_name = \"filterList_test_2.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'test/'\n",
    "    file_name = \"filterList_test_2.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"rows!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "\n",
    "    for i in range(0,209):\n",
    "            print(write_CSV(get_class_data(urllist[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e0b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(hidden_layer_sizes=(8, 8, 8), max_iter=500))])\n",
      "==================================================================\n",
      "Fold:  1\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  2\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  3\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  4\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  5\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Average class 0 precision = 99.0\n",
      "Average class 1 precision = 100.0\n",
      "Average class 0 recall = 100.0\n",
      "Average class 1 recall = 98.9\n",
      "Average accuracy = 99.5\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "# lr = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', solver='liblinear',tol=1e-6,warm_start=True, intercept_scaling=10000.))\n",
    "mlp = make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500))\n",
    "# svc = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "# dt = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "# knn = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "_classifier_ = []\n",
    "# _classifier_.append(lr)\n",
    "_classifier_.append(mlp)\n",
    "# _classifier_.append(svc)\n",
    "# _classifier_.append(dt)\n",
    "# _classifier_.append(knn)  \n",
    "\n",
    "def process(model):\n",
    "    p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "    csv_df = pd.read_csv(\"test/filterList_test_2.csv\")\n",
    "    filtered_one = csv_df[csv_df['filterClass'] != 0] \n",
    "    filtered_zero = csv_df[csv_df['filterClass'] == 0] \n",
    "    f_o = filtered_zero.sample(n=1621,replace=False)\n",
    "    z = pd.concat([filtered_one, f_o], axis=0)\n",
    "    z  = z.reset_index(drop=True)\n",
    "    x_2 = z[['checkBoxList','NumberOfLink','NumberOfInput','URL_List','button_List']]\n",
    "    y_2 = z[[\"filterClass\"]]\n",
    "        \n",
    "    fivefold = [\n",
    "             (np.r_[1:1297,1621:2918], np.r_[1297:1621,2918:3242]),\n",
    "             (np.r_[1:1000,1324:2000, 2324:3242], np.r_[1000:1324, 2000:2324]),\n",
    "             (np.r_[1:676, 1000:1676,2000:3242], np.r_[676:1000,1676:2000]),\n",
    "             (np.r_[1:400, 562:800, 862:1700, 1862:2500, 2662:3242], np.r_[400:562, 800:862,1700:1862,2500:2662]),\n",
    "             (np.r_[1:638,800:1297,1459:2000,2162:3080], np.r_[638:800,1297:1459, 2000:2162,3080:3242])\n",
    "    ]\n",
    "    print(\"==================================================================\")\n",
    "    print(model)\n",
    "    print(\"==================================================================\")\n",
    "    fold = 1\n",
    "    for train_index, test_index in fivefold:\n",
    "        print(\"Fold: \",fold)\n",
    "        x_train, X_test, y_train, y_test = x_2.iloc[train_index], x_2.iloc[test_index], y_2.iloc[train_index], y_2.iloc[test_index]\n",
    "        print(\"==================================================================\")\n",
    "        model.fit(x_train, y_train)\n",
    "        model_pred = model.predict(X_test)\n",
    "        filename = '/Users/mdjavedulferdous/Desktop/TiiS/Code/filter_model_2.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        #print(classification_report(y_test, model_pred))\n",
    "        cv_results = model_selection.cross_val_score(model, x_train, y_train).mean()\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, model_pred).ravel()\n",
    "        #print(\"True negative: %s \\nFalse positive: %s \\nFalse negative: %s \\nTrue positive: %s\\n\\n\" % (tn, fp, fn, tp))\n",
    "        print(\"==================================================================\")\n",
    "        cDF = pd.DataFrame(model_pred)\n",
    "        y_test = np.asarray(y_test)\n",
    "        misclassified = [i for i in range(len(model_pred)) if model_pred[i] != y_test[i]]\n",
    "        #if misclassified ==[]:\n",
    "        #    print(\"No misclassified index detected\")\n",
    "        #else:\n",
    "       #     for i in misclassified:\n",
    "        #        print(\"Misclassified index: \", i)\n",
    "        precision = precision_score(y_test, model_pred, average=None)\n",
    "        p_class_0.append(precision[0])\n",
    "        p_class_1.append(precision[1])\n",
    "        recall = recall_score(y_test, model_pred, average=None)\n",
    "        r_class_0.append(recall[0])\n",
    "        r_class_1.append(recall[1])\n",
    "        print(\"==================================================================\")\n",
    "        fold +=1\n",
    "    return p_class_0,p_class_1, r_class_0, r_class_1, cv_results\n",
    "for i in _classifier_:\n",
    "    p_class_0,p_class_1, r_class_0, r_class_1, acc = process(i)\n",
    "    print(\"==================================================================\")\n",
    "    print('Average class 0 precision = {:.1f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "    print('Average class 1 precision = {:.1f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "    print('Average class 0 recall = {:.1f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "    print('Average class 1 recall = {:.1f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "    print('Average accuracy = {:.1f}'.format(acc*100))\n",
    "    print(\"==================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a748af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "MLPClassifier(hidden_layer_sizes=(8, 8, 8), max_iter=500)\n",
      "==================================================================\n",
      "Fold:  1\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdjavedulferdous/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  2\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdjavedulferdous/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  3\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdjavedulferdous/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/mdjavedulferdous/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  4\n",
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Fold:  5\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdjavedulferdous/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/mdjavedulferdous/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "==================================================================\n",
      "==================================================================\n",
      "Average class 0 precision = 87.4\n",
      "Average class 1 precision = 100.0\n",
      "Average class 0 recall = 100.0\n",
      "Average class 1 recall = 81.5\n",
      "Average accuracy = 94.2\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "from init import *\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear',tol=1e-6,warm_start=True, intercept_scaling=10000.)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
    "svc =SVC(kernel='rbf')\n",
    "dt = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "_classifier_ = []\n",
    "# _classifier_.append(lr)\n",
    "_classifier_.append(mlp)\n",
    "# _classifier_.append(svc)\n",
    "# _classifier_.append(dt)\n",
    "# _classifier_.append(knn)  \n",
    "\n",
    "def process(model):\n",
    "    p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "    csv_df = pd.read_csv(\"/Users/mdjavedulferdous/Documents/Dataset/New Dataset/sort_version_two.csv\")\n",
    "    filtered_one = csv_df[csv_df['sortClass'] != 0] \n",
    "    filtered_zero = csv_df[csv_df['sortClass'] == 0] \n",
    "    f_o = filtered_zero.sample(n=209,replace=False)\n",
    "    z = pd.concat([filtered_one, f_o], axis=0)\n",
    "    z  = z.reset_index(drop=True)\n",
    "    x_2 = z[['sort_inner','sort_attribute','option_tag_attribute_value','textCount']]\n",
    "    y_2 = z[[\"sortClass\"]]\n",
    "        \n",
    "    fivefold = [\n",
    "             (np.r_[1:168,209:335,376:418], np.r_[168:209,335:376]),\n",
    "             (np.r_[1:83,124:239, 280:418], np.r_[83:124, 239:280]),\n",
    "             (np.r_[1:124, 165:377], np.r_[124:165,377:418]),\n",
    "             (np.r_[1:168, 251:418], np.r_[168:251]),\n",
    "             (np.r_[1:100,142:209,250:418], np.r_[100:142, 209:250])\n",
    "    ]\n",
    "    print(\"==================================================================\")\n",
    "    print(model)\n",
    "    print(\"==================================================================\")\n",
    "    fold = 1\n",
    "    for train_index, test_index in fivefold:\n",
    "        print(\"Fold: \",fold)\n",
    "        x_train, X_test, y_train, y_test = x_2.iloc[train_index], x_2.iloc[test_index], y_2.iloc[train_index], y_2.iloc[test_index]\n",
    "        print(\"==================================================================\")\n",
    "        model.fit(x_train, y_train)\n",
    "        # save the model to disk\n",
    "        filename = '/Users/mdjavedulferdous/Desktop/TiiS/Code/sort_model_2.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        model_pred = model.predict(X_test)\n",
    "        #print(classification_report(y_test, model_pred))\n",
    "        cv_results = model_selection.cross_val_score(model, x_train, y_train).mean()\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, model_pred).ravel()\n",
    "        #print(\"True negative: %s \\nFalse positive: %s \\nFalse negative: %s \\nTrue positive: %s\\n\\n\" % (tn, fp, fn, tp))\n",
    "        print(\"==================================================================\")\n",
    "        cDF = pd.DataFrame(model_pred)\n",
    "        y_test = np.asarray(y_test)\n",
    "        misclassified = [i for i in range(len(model_pred)) if model_pred[i] != y_test[i]]\n",
    "        #if misclassified ==[]:\n",
    "        #    print(\"No misclassified index detected\")\n",
    "        #else:\n",
    "       #     for i in misclassified:\n",
    "        #        print(\"Misclassified index: \", i)\n",
    "        precision = precision_score(y_test, model_pred, average=None)\n",
    "        p_class_0.append(precision[0])\n",
    "        p_class_1.append(precision[1])\n",
    "        recall = recall_score(y_test, model_pred, average=None)\n",
    "        r_class_0.append(recall[0])\n",
    "        r_class_1.append(recall[1])\n",
    "        print(\"==================================================================\")\n",
    "        fold +=1\n",
    "    return p_class_0,p_class_1, r_class_0, r_class_1, cv_results\n",
    "for i in _classifier_:\n",
    "    p_class_0,p_class_1, r_class_0, r_class_1, acc = process(i)\n",
    "    print(\"==================================================================\")\n",
    "    print('Average class 0 precision = {:.1f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "    print('Average class 1 precision = {:.1f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "    print('Average class 0 recall = {:.1f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "    print('Average class 1 recall = {:.1f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "    print('Average accuracy = {:.1f}'.format(acc*100))\n",
    "    print(\"==================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16bbe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from init import *\n",
    "from testURL import *\n",
    "def sortFunc(_url_):\n",
    "    new_count= 0 \n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    \n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    selectSearch = soup.findAll('select',{\"data-attribute\":\"sort\"})\n",
    "    ulSearch = soup.findAll('ul',{\"data-attribute\":\"sort\"})\n",
    "    \n",
    "    divSearch = soup.findAll('div',{\"data-attribute\":\"sort\"})\n",
    " \n",
    "    #print(soup.findAll(text=re.compile('^Sort By$')))\n",
    "    #print(len(soup.findAll(text=re.compile(\".*sort .*\"))))\n",
    "\n",
    "    if selectSearch != []:\n",
    "        #print(\"Select\")\n",
    "        for tests in soup.findAll('select'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            new_count +=(int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended))\n",
    "        t_count.append(new_count)\n",
    "        if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                    sortClass.append(1)\n",
    "                    if \" \" == tests.text:\n",
    "                        sort_inner.append(0)             \n",
    "                    else:\n",
    "                        if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                                sort_inner.append(1)\n",
    "                        else:\n",
    "                                sort_inner.append(0)             \n",
    "                    if('sort' in list(tests.attrs.values())):\n",
    "                        sort_attribute.append(1)\n",
    "                    else:\n",
    "                        sort_attribute.append(0)\n",
    "                    optionTag = tests.findAll(\"li\")\n",
    "                    option_tag_attribute_value.append(len(optionTag))\n",
    "    elif ulSearch != []:\n",
    "        #print(\"UL\")\n",
    "        for tests in soup.findAll('ul'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            new_count +=(int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended))\n",
    "        t_count.append(new_count)\n",
    "        if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                    sortClass.append(1)\n",
    "                    if \" \" == tests.text:\n",
    "                        sort_inner.append(0)             \n",
    "                    else:\n",
    "                        if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                                sort_inner.append(1)\n",
    "                        else:\n",
    "                                sort_inner.append(0)             \n",
    "                    if('sort' in list(tests.attrs.values())):\n",
    "                        sort_attribute.append(1)\n",
    "                    else:\n",
    "                        sort_attribute.append(0)\n",
    "                    optionTag = tests.findAll(\"li\")\n",
    "                    option_tag_attribute_value.append(len(optionTag))\n",
    "       \n",
    "            \n",
    "\n",
    "    if (sort_inner ==[]):\n",
    "        sort_inner = [0]\n",
    "    if (sort_attribute ==[]):\n",
    "        sort_attribute = [0]\n",
    "    if (option_tag_attribute_value ==[]):\n",
    "        option_tag_attribute_value = [0]\n",
    "    if (sortClass ==[]):\n",
    "        sortClass = [0]\n",
    "    if (t_count ==[]):\n",
    "        t_count = [0]    \n",
    "    temp = len(sortClass)*[_url_]\n",
    "    return temp, sort_inner,  option_tag_attribute_value, sort_attribute, sortClass,t_count\n",
    "for i in range(len(turl)):\n",
    "    print(sortFunc(turl[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e8004a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/1mg.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/99acres.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Activewear.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Ajio.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/aliexpress.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/AmericanEagle.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Apartments.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Apparel.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Argos.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/ASOS.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Aurate.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Bata.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Bath_Body Works.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Bewakoof.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/bigbasket.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/boohoo.html\n",
      "None\n",
      "0 /Users/mdjavedulferdous/Documents/Dataset/Testing/CanadianTire.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/century.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/CENTURY21.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Chumbak.html\n",
      "None\n",
      "0 /Users/mdjavedulferdous/Documents/Dataset/Testing/Cleartrip.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/coldwellbankerhomes.html\n",
      "None\n",
      "0 /Users/mdjavedulferdous/Documents/Dataset/Testing/Commonfloor.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/COSRX.html\n",
      "None\n",
      "0 /Users/mdjavedulferdous/Documents/Dataset/Testing/Coursera.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Crocs.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Croma.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Currys.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Decathlon.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Dell.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Dineout.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/DuProprio.html\n",
      "None\n",
      "0 /Users/mdjavedulferdous/Documents/Dataset/Testing/eBay_Art.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Express.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Fabindia.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/FARFETCH.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/fashionphile.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/FirstCry.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Flipkart.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Foreclosures.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Forever21.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/freepeople.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/FSBO.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Gumtree.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Hayneedle.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/HimalayaWellness.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/Homes.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/HomeShopping.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/ITCStore.html\n",
      "None\n",
      "1 /Users/mdjavedulferdous/Documents/Dataset/Testing/John_sCrazySocks.html\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/sxpbd7294kg6s7m7cz0pcn6h0000gn/T/ipykernel_5742/2469274438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m#return temp, sort_inner,  option_tag_attribute_value, sort_attribute, sortClass,t_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msortFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/ll/sxpbd7294kg6s7m7cz0pcn6h0000gn/T/ipykernel_5742/2469274438.py\u001b[0m in \u001b[0;36msortFunc\u001b[0;34m(_url_)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mt_Most\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".*Most recent.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mt_New\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".*New.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mt_Best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".*Best Match.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mt_Highest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".*Highest*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mt_Ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".*Ratings.*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[0;31m# BS3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m     \u001b[0mfindChildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m  \u001b[0;31m# BS2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m                  \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2149\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2150\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   2224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_against\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m             \u001b[0;31m# Regexp match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2226\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         if (not match\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sortFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    \n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    selectSearch = soup.findAll('select',{\"data-attribute\":\"sort\"})\n",
    "    ulSearch = soup.findAll('ul',{\"data-attribute\":\"sort\"})\n",
    "    divSearch = soup.findAll('div',{\"data-attribute\":\"sort\"})\n",
    "    spanSearch = soup.findAll('span',{\"data-attribute\":\"sort\"})\n",
    "\n",
    "    if selectSearch != []:\n",
    "        #print(\"Select\")\n",
    "        for tests in soup.findAll('select'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"option\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "    elif spanSearch != []:\n",
    "        for tests in soup.findAll('span'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"option\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "    elif divSearch != []:\n",
    "        for tests in soup.findAll('div'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"option\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "    elif ulSearch != []:\n",
    "        #print(\"UL\")\n",
    "        for tests in soup.findAll('ul'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"li\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "\n",
    "\n",
    "    if (sort_inner ==[]):\n",
    "        sort_inner = [0]\n",
    "    if (sort_attribute ==[]):\n",
    "        sort_attribute = [0]\n",
    "    if (option_tag_attribute_value ==[]):\n",
    "        option_tag_attribute_value = [0]\n",
    "    if (sortClass ==[]):\n",
    "        sortClass = [0]\n",
    "    if (t_count ==[]):\n",
    "        t_count = [0]    \n",
    "    temp = len(sort_inner)*[_url_]\n",
    "    t_count =[max(t_count)]\n",
    "    print(sortClass[0],temp[0])\n",
    "    #return temp, sort_inner,  option_tag_attribute_value, sort_attribute, sortClass,t_count\n",
    "for i in range(len(turl)):\n",
    "    print(sortFunc(turl[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e7fa515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 ]. form!\n",
      "None\n",
      "[ 52 ]. form!\n",
      "None\n",
      "[ 53 ]. form!\n",
      "None\n",
      "[ 54 ]. form!\n",
      "None\n",
      "[ 55 ]. form!\n",
      "None\n",
      "[ 56 ]. form!\n",
      "None\n",
      "[ 57 ]. form!\n",
      "None\n",
      "[ 58 ]. form!\n",
      "None\n",
      "[ 59 ]. form!\n",
      "None\n",
      "[ 146 ]. form!\n",
      "None\n",
      "[ 147 ]. form!\n",
      "None\n",
      "[ 148 ]. form!\n",
      "None\n",
      "[ 149 ]. form!\n",
      "None\n",
      "[ 172 ]. form!\n",
      "None\n",
      "[ 173 ]. form!\n",
      "None\n",
      "[ 174 ]. form!\n",
      "None\n",
      "[ 254 ]. form!\n",
      "None\n",
      "[ 304 ]. form!\n",
      "None\n",
      "[ 305 ]. form!\n",
      "None\n",
      "[ 306 ]. form!\n",
      "None\n",
      "[ 315 ]. form!\n",
      "None\n",
      "[ 685 ]. form!\n",
      "None\n",
      "[ 686 ]. form!\n",
      "None\n",
      "[ 711 ]. form!\n",
      "None\n",
      "[ 712 ]. form!\n",
      "None\n",
      "[ 713 ]. form!\n",
      "None\n",
      "[ 732 ]. form!\n",
      "None\n",
      "[ 733 ]. form!\n",
      "None\n",
      "[ 734 ]. form!\n",
      "None\n",
      "[ 735 ]. form!\n",
      "None\n",
      "[ 914 ]. form!\n",
      "None\n",
      "[ 915 ]. form!\n",
      "None\n",
      "[ 916 ]. form!\n",
      "None\n",
      "[ 917 ]. form!\n",
      "None\n",
      "[ 918 ]. form!\n",
      "None\n",
      "[ 919 ]. form!\n",
      "None\n",
      "[ 920 ]. form!\n",
      "None\n",
      "[ 921 ]. form!\n",
      "None\n",
      "[ 922 ]. form!\n",
      "None\n",
      "[ 923 ]. form!\n",
      "None\n",
      "[ 924 ]. form!\n",
      "None\n",
      "[ 959 ]. form!\n",
      "None\n",
      "[ 960 ]. form!\n",
      "None\n",
      "[ 987 ]. form!\n",
      "None\n",
      "[ 988 ]. form!\n",
      "None\n",
      "[ 989 ]. form!\n",
      "None\n",
      "[ 990 ]. form!\n",
      "None\n",
      "[ 1003 ]. form!\n",
      "None\n",
      "[ 1056 ]. form!\n",
      "None\n",
      "[ 1099 ]. form!\n",
      "None\n",
      "[ 1128 ]. form!\n",
      "None\n",
      "[ 1129 ]. form!\n",
      "None\n",
      "[ 1130 ]. form!\n",
      "None\n",
      "[ 1131 ]. form!\n",
      "None\n",
      "[ 1132 ]. form!\n",
      "None\n",
      "[ 1133 ]. form!\n",
      "None\n",
      "[ 1134 ]. form!\n",
      "None\n",
      "[ 1135 ]. form!\n",
      "None\n",
      "[ 1136 ]. form!\n",
      "None\n",
      "[ 1137 ]. form!\n",
      "None\n",
      "[ 1138 ]. form!\n",
      "None\n",
      "[ 1139 ]. form!\n",
      "None\n",
      "[ 1140 ]. form!\n",
      "None\n",
      "[ 1141 ]. form!\n",
      "None\n",
      "[ 1259 ]. form!\n",
      "None\n",
      "[ 1304 ]. form!\n",
      "None\n",
      "[ 1315 ]. form!\n",
      "None\n",
      "[ 1316 ]. form!\n",
      "None\n",
      "[ 1317 ]. form!\n",
      "None\n",
      "[ 1318 ]. form!\n",
      "None\n",
      "[ 1319 ]. form!\n",
      "None\n",
      "[ 1320 ]. form!\n",
      "None\n",
      "[ 1353 ]. form!\n",
      "None\n",
      "[ 1369 ]. form!\n",
      "None\n",
      "[ 1370 ]. form!\n",
      "None\n",
      "[ 1371 ]. form!\n",
      "None\n",
      "[ 1372 ]. form!\n",
      "None\n",
      "[ 1373 ]. form!\n",
      "None\n",
      "[ 1374 ]. form!\n",
      "None\n",
      "[ 1375 ]. form!\n",
      "None\n",
      "[ 1376 ]. form!\n",
      "None\n",
      "[ 1377 ]. form!\n",
      "None\n",
      "[ 1378 ]. form!\n",
      "None\n",
      "[ 1418 ]. form!\n",
      "None\n",
      "[ 1419 ]. form!\n",
      "None\n",
      "[ 1485 ]. form!\n",
      "None\n",
      "[ 1486 ]. form!\n",
      "None\n",
      "[ 1487 ]. form!\n",
      "None\n",
      "[ 1541 ]. form!\n",
      "None\n",
      "[ 1542 ]. form!\n",
      "None\n",
      "[ 1592 ]. form!\n",
      "None\n",
      "[ 1618 ]. form!\n",
      "None\n",
      "[ 1619 ]. form!\n",
      "None\n",
      "[ 1620 ]. form!\n",
      "None\n",
      "[ 1621 ]. form!\n",
      "None\n",
      "[ 1622 ]. form!\n",
      "None\n",
      "[ 1623 ]. form!\n",
      "None\n",
      "[ 1624 ]. form!\n",
      "None\n",
      "[ 1625 ]. form!\n",
      "None\n",
      "[ 1695 ]. form!\n",
      "None\n",
      "[ 1696 ]. form!\n",
      "None\n",
      "[ 1697 ]. form!\n",
      "None\n",
      "[ 1698 ]. form!\n",
      "None\n",
      "[ 1699 ]. form!\n",
      "None\n",
      "[ 1700 ]. form!\n",
      "None\n",
      "[ 1730 ]. form!\n",
      "None\n",
      "[ 1731 ]. form!\n",
      "None\n",
      "[ 1732 ]. form!\n",
      "None\n",
      "[ 1733 ]. form!\n",
      "None\n",
      "[ 1734 ]. form!\n",
      "None\n",
      "[ 1735 ]. form!\n",
      "None\n",
      "[ 1736 ]. form!\n",
      "None\n",
      "[ 1737 ]. form!\n",
      "None\n",
      "[ 1738 ]. form!\n",
      "None\n",
      "[ 1766 ]. form!\n",
      "None\n",
      "[ 1767 ]. form!\n",
      "None\n",
      "[ 1768 ]. form!\n",
      "None\n",
      "[ 1769 ]. form!\n",
      "None\n",
      "[ 1991 ]. form!\n",
      "None\n",
      "[ 1992 ]. form!\n",
      "None\n",
      "[ 1993 ]. form!\n",
      "None\n",
      "[ 1994 ]. form!\n",
      "None\n",
      "[ 1995 ]. form!\n",
      "None\n",
      "[ 1996 ]. form!\n",
      "None\n",
      "[ 1997 ]. form!\n",
      "None\n",
      "[ 1998 ]. form!\n",
      "None\n",
      "[ 2099 ]. form!\n",
      "None\n",
      "[ 2100 ]. form!\n",
      "None\n",
      "[ 2289 ]. form!\n",
      "None\n",
      "[ 2290 ]. form!\n",
      "None\n",
      "[ 2291 ]. form!\n",
      "None\n",
      "[ 2321 ]. form!\n",
      "None\n",
      "[ 2322 ]. form!\n",
      "None\n",
      "[ 2358 ]. form!\n",
      "None\n",
      "[ 2359 ]. form!\n",
      "None\n",
      "[ 2360 ]. form!\n",
      "None\n",
      "[ 2361 ]. form!\n",
      "None\n",
      "[ 2362 ]. form!\n",
      "None\n",
      "[ 2363 ]. form!\n",
      "None\n",
      "[ 2547 ]. form!\n",
      "None\n",
      "[ 2548 ]. form!\n",
      "None\n",
      "[ 2549 ]. form!\n",
      "None\n",
      "[ 2550 ]. form!\n",
      "None\n",
      "[ 2623 ]. form!\n",
      "None\n",
      "[ 2624 ]. form!\n",
      "None\n",
      "[ 2625 ]. form!\n",
      "None\n",
      "[ 2626 ]. form!\n",
      "None\n",
      "[ 2627 ]. form!\n",
      "None\n",
      "[ 2707 ]. form!\n",
      "None\n",
      "[ 2788 ]. form!\n",
      "None\n",
      "[ 2789 ]. form!\n",
      "None\n",
      "[ 2796 ]. form!\n",
      "None\n",
      "[ 2866 ]. form!\n",
      "None\n",
      "[ 2867 ]. form!\n",
      "None\n",
      "[ 2868 ]. form!\n",
      "None\n",
      "[ 2869 ]. form!\n",
      "None\n",
      "[ 2885 ]. form!\n",
      "None\n",
      "[ 2886 ]. form!\n",
      "None\n",
      "[ 2887 ]. form!\n",
      "None\n",
      "[ 2888 ]. form!\n",
      "None\n",
      "[ 2942 ]. form!\n",
      "None\n",
      "[ 2943 ]. form!\n",
      "None\n",
      "[ 2985 ]. form!\n",
      "None\n",
      "[ 2986 ]. form!\n",
      "None\n",
      "[ 3139 ]. form!\n",
      "None\n",
      "[ 3140 ]. form!\n",
      "None\n",
      "[ 3342 ]. form!\n",
      "None\n",
      "[ 3343 ]. form!\n",
      "None\n",
      "[ 3344 ]. form!\n",
      "None\n",
      "[ 3345 ]. form!\n",
      "None\n",
      "[ 3346 ]. form!\n",
      "None\n",
      "[ 3347 ]. form!\n",
      "None\n",
      "[ 3401 ]. form!\n",
      "None\n",
      "[ 3402 ]. form!\n",
      "None\n",
      "[ 3403 ]. form!\n",
      "None\n",
      "[ 3404 ]. form!\n",
      "None\n",
      "[ 3405 ]. form!\n",
      "None\n",
      "[ 3500 ]. form!\n",
      "None\n",
      "[ 3737 ]. form!\n",
      "None\n",
      "[ 3738 ]. form!\n",
      "None\n",
      "[ 3790 ]. form!\n",
      "None\n",
      "[ 3791 ]. form!\n",
      "None\n",
      "[ 3792 ]. form!\n",
      "None\n",
      "[ 3837 ]. form!\n",
      "None\n",
      "[ 3838 ]. form!\n",
      "None\n",
      "[ 3839 ]. form!\n",
      "None\n",
      "[ 3897 ]. form!\n",
      "None\n",
      "[ 3898 ]. form!\n",
      "None\n",
      "[ 3899 ]. form!\n",
      "None\n",
      "[ 3900 ]. form!\n",
      "None\n",
      "[ 3901 ]. form!\n",
      "None\n",
      "[ 3935 ]. form!\n",
      "None\n",
      "[ 3936 ]. form!\n",
      "None\n",
      "[ 3937 ]. form!\n",
      "None\n",
      "[ 3938 ]. form!\n",
      "None\n",
      "[ 3939 ]. form!\n",
      "None\n",
      "[ 3940 ]. form!\n",
      "None\n",
      "[ 3941 ]. form!\n",
      "None\n",
      "[ 3988 ]. form!\n",
      "None\n",
      "[ 3989 ]. form!\n",
      "None\n",
      "[ 3990 ]. form!\n",
      "None\n",
      "[ 3991 ]. form!\n",
      "None\n",
      "[ 3992 ]. form!\n",
      "None\n",
      "[ 4005 ]. form!\n",
      "None\n",
      "[ 4006 ]. form!\n",
      "None\n",
      "[ 4007 ]. form!\n",
      "None\n",
      "[ 4008 ]. form!\n",
      "None\n",
      "[ 4009 ]. form!\n",
      "None\n",
      "[ 4010 ]. form!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from init import *\n",
    "from allURL import *\n",
    "\n",
    "def sortFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    \n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    selectSearch = soup.findAll('select',{\"data-attribute\":\"sort\"})\n",
    "    ulSearch = soup.findAll('ul',{\"data-attribute\":\"sort\"})\n",
    "    divSearch = soup.findAll('div',{\"data-attribute\":\"sort\"})\n",
    "    spanSearch = soup.findAll('span',{\"data-attribute\":\"sort\"})\n",
    "\n",
    "    if selectSearch != []:\n",
    "        #print(\"Select\")\n",
    "        for tests in soup.findAll('select'):\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "                t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "                t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "                t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "                t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "                t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "                t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "                t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "                t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "                t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "                t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "                t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"option\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "    elif spanSearch != []:\n",
    "        for tests in soup.findAll('span'):\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "                t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "                t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "                t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "                t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "                t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "                t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "                t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "                t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "                t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "                t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "                t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"option\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "    elif divSearch != []:\n",
    "        for tests in soup.findAll('div'):\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "                t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "                t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "                t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "                t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "                t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "                t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "                t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "                t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "                t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "                t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "                t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"option\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "    elif ulSearch != []:\n",
    "        #print(\"UL\")\n",
    "        for tests in soup.findAll('ul'):\n",
    "            \n",
    "            if \"data-attribute\" in list(tests.attrs.keys()) and \"sort\" in list(tests.attrs.values()):\n",
    "                t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "                t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "                t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "                t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "                t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "                t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "                t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "                t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "                t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "                t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "                t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "                t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "                sortClass.append(1)\n",
    "                if \" \" == tests.text:\n",
    "                    sort_inner.append(0)             \n",
    "                else:\n",
    "                    #print(tests.text)\n",
    "                    if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                        #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                        sort_inner.append(1)\n",
    "                    else:\n",
    "                        sort_inner.append(0)             \n",
    "                if('sort' in list(tests.attrs.values())):\n",
    "                    #print(tests.attrs.values())\n",
    "                    sort_attribute.append(1)\n",
    "                else:\n",
    "                    sort_attribute.append(0) \n",
    "                optionTag = tests.findAll(\"li\")\n",
    "                option_tag_attribute_value.append(len(optionTag))\n",
    "            else:\n",
    "                sort_inner.append(0)   \n",
    "                option_tag_attribute_value.append(0) \n",
    "                sort_attribute.append(0) \n",
    "                sortClass.append(0) \n",
    "                t_count.append(0) \n",
    "\n",
    "    if (sort_inner ==[]):\n",
    "        sort_inner = [0]\n",
    "    if (sort_attribute ==[]):\n",
    "        sort_attribute = [0]\n",
    "    if (option_tag_attribute_value ==[]):\n",
    "        option_tag_attribute_value = [0]\n",
    "    if (sortClass ==[]):\n",
    "        sortClass = [0]\n",
    "    if (t_count ==[]):\n",
    "        t_count = [0]    \n",
    "    temp = len(sortClass)*[_url_]\n",
    "    #t_count =[max(t_count)]\n",
    "    return temp, sort_inner,  option_tag_attribute_value, sort_attribute, sortClass,t_count\n",
    "def get_class_data(searchQ) :\n",
    "        name_url, sort_inner, option_tag_attribute_value, sort_attribute, sortClass, textCount = sortFunc(searchQ)\n",
    "        sort_inner = str(sort_inner)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        sort_attribute = str(sort_attribute)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #option_tag_attribute_value = str(option_tag_attribute_value)[1:-1]\n",
    "        sortClass = str(sortClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in sort_inner:\n",
    "            sort_inner = i\n",
    "            temp.append([sort_inner])        \n",
    "        \n",
    "        t_sort_attribute = []\n",
    "        for m in sort_attribute:\n",
    "            t_sort_attribute.append(m)\n",
    "        arr2d = np.matrix(temp)\n",
    "        column_to_add = np.array(t_sort_attribute)\n",
    "        output = np.column_stack((arr2d, column_to_add))\n",
    "        f_sort_attribute = output.tolist()\n",
    "        \n",
    "        t_option = []\n",
    "        for m in option_tag_attribute_value:\n",
    "            t_option.append(m)\n",
    "        option_arr2d = np.matrix(f_sort_attribute)\n",
    "        option_to_add = np.array(t_option)\n",
    "        output_option = np.column_stack((option_arr2d, option_to_add))\n",
    "        f_option = output_option.tolist()\n",
    "\n",
    "        t_sortClass = []\n",
    "        for m in sortClass:\n",
    "            t_sortClass.append(m)\n",
    "        sortClass_arr2d = np.matrix(f_option)\n",
    "        sortClass_add = np.array(t_sortClass)\n",
    "        sortClass_output = np.column_stack((sortClass_arr2d, sortClass_add))\n",
    "        f_sortClass = sortClass_output.tolist()\n",
    "        \n",
    "        t_textCount = []\n",
    "        for m in textCount:\n",
    "            t_textCount.append(m)\n",
    "        textCount_arr2d = np.matrix(f_sortClass)\n",
    "        textCount_add = np.array(t_textCount)\n",
    "        textCount_output = np.column_stack((textCount_arr2d, textCount_add))\n",
    "        f_textCount = textCount_output.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_textCount)\n",
    "        column_name = np.array(t_name)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "\n",
    "        return f_name\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"sort_inner\", \"sort_attribute\", \"option_tag_attribute_value\",\"sortClass\",\"textCount\",\"name_url\"]\n",
    "    save_path = 'test/'\n",
    "    file_name = \"sort_test_2.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'test/'\n",
    "    file_name = \"sort_test_2.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,209):\n",
    "            print(write_CSV(get_class_data(urllist[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "101e4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mdjavedulferdous/Documents/Dataset/New Dataset\n"
     ]
    }
   ],
   "source": [
    "cd \"/Users/mdjavedulferdous/Documents/Dataset/New Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4768e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
