{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde454bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "from testURL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107dfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/mdjavedulferdous/Documents/Dataset/Testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875b22e",
   "metadata": {},
   "source": [
    "### Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778128aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "from allURL import *\n",
    "\n",
    "def search(myDict, search1):\n",
    "    search.a=[]\n",
    "    for key, value in myDict.items():\n",
    "        if search1 in value:\n",
    "            search.a.append(key)\n",
    "    return len(search.a)\n",
    "\n",
    "def search_query(_url_):\n",
    "    s_inner,is_button,search_attribute, noWord, sClass,search_button_attribute_value  = ([] for i in range(6)) \n",
    "    BnoWord = 0\n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    #print(soup)\n",
    "    try:\n",
    "        for tests in soup.findAll('form'):\n",
    "            my_attributes = tests.attrs\n",
    "            #print(my_attributes)\n",
    "            if \"data-attribute\" in list(my_attributes.keys()):\n",
    "                if \"search\" in list(my_attributes.values()):\n",
    "                    sClass.append(1)\n",
    "                else:\n",
    "                    sClass.append(0)\n",
    "            else:\n",
    "                sClass.append(0)\n",
    "            if('search' in list(tests.attrs.values())):\n",
    "                search_attribute.append(1)\n",
    "            else:\n",
    "                search_attribute.append(0) \n",
    "            if \" \" == tests.text:\n",
    "                s_inner.append(0)\n",
    "                \n",
    "            else:\n",
    "                s_inner.append(1)                \n",
    "            my_no = tests.attrs\n",
    "            noWord.append(search(my_no, \"search\"))\n",
    "            \n",
    "            is_present = bool(re.search('button', str(tests)))\n",
    "            if(is_present == True):\n",
    "                is_button.append(1)\n",
    "            else:\n",
    "                is_button.append(0)\n",
    "                \n",
    "            if \"data-attribute\" in list(my_attributes.keys()):    \n",
    "                buttonSearch = tests.find(\"button\")\n",
    "                button_attributes = buttonSearch.attrs\n",
    "                BnoWord = search(button_attributes, \"search\")\n",
    "                if(BnoWord == 1):\n",
    "                    search_button_attribute_value.append(1)\n",
    "                else:\n",
    "                    search_button_attribute_value.append(0)\n",
    "            else:\n",
    "                search_button_attribute_value.append(0)\n",
    "            \n",
    "    except:\n",
    "        search_button_attribute_value.append(0)\n",
    "    \n",
    "    if (s_inner ==[]):\n",
    "        s_inner = [0]\n",
    "    if (search_attribute ==[]):\n",
    "        search_attribute = [0]\n",
    "    if (noWord ==[]):\n",
    "        noWord = [0]\n",
    "    if (is_button ==[]):\n",
    "        is_button = [0]\n",
    "    if (search_button_attribute_value ==[]):\n",
    "        search_button_attribute_value = [0]    \n",
    "    if (sClass ==[]):\n",
    "        sClass = [1]\n",
    "    \n",
    "    temp = len(s_inner)*[_url_]\n",
    "    \n",
    "    return temp,s_inner, search_attribute,noWord,is_button, search_button_attribute_value,sClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(searchQ) :\n",
    "        name_url, search_innertext,search_attribute,noWord, is_button, search_button_attribute_value, sClass = search_query(searchQ)\n",
    "        search_innertext = str(search_innertext)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        search_attribute = str(search_attribute)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        noWord = str(noWord)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        is_button = str(is_button)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        search_button_attribute_value = str(search_button_attribute_value)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        sClass = str(sClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        \n",
    "        for i in search_innertext:\n",
    "            search_innertext = i\n",
    "            temp.append([search_innertext])        \n",
    "            \n",
    "        t_search_attribute = []\n",
    "        for m in search_attribute:\n",
    "            t_search_attribute.append(m)\n",
    "        arr2d = np.matrix(temp)\n",
    "        column_to_add = np.array(t_search_attribute)\n",
    "        output = np.column_stack((arr2d, column_to_add))\n",
    "        f_search_attribute = output.tolist()\n",
    "        \n",
    "        t_noWord = []\n",
    "        for m in noWord:\n",
    "            t_noWord.append(m)\n",
    "        a_noWord = np.matrix(f_search_attribute)\n",
    "        column_noWord = np.array(t_noWord)\n",
    "        o_noWord = np.column_stack((a_noWord, column_noWord))\n",
    "        f_noWord = o_noWord.tolist()        \n",
    "        \n",
    "        t_is_button= []\n",
    "        for m in is_button:\n",
    "            t_is_button.append(m)\n",
    "        a_is_button = np.matrix(f_noWord)\n",
    "        column_is_button= np.array(t_is_button)\n",
    "        o_is_button = np.column_stack((a_is_button, column_is_button))\n",
    "        f_is_button= o_is_button.tolist()        \n",
    "        \n",
    "        t_s_value= []\n",
    "        for m in search_button_attribute_value:\n",
    "            t_s_value.append(m)\n",
    "        a_s_value = np.matrix(f_is_button)\n",
    "        column_s_value= np.array(t_s_value)\n",
    "        o_s_value = np.column_stack((a_s_value, column_s_value))\n",
    "        f_s_value= o_s_value.tolist()\n",
    "        \n",
    "        t_sClass= []\n",
    "        for m in sClass:\n",
    "            t_sClass.append(m)\n",
    "        a_sClass = np.matrix(f_s_value)\n",
    "        column_sClass= np.array(t_sClass)\n",
    "        o_sClass = np.column_stack((a_sClass, column_sClass))\n",
    "        f_sClass= o_sClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_sClass)\n",
    "        column_name = np.array(t_name)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        return f_name\n",
    "#get_class_data(url_104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5828c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header():\n",
    "    list_of_header = [\"search_innertext\", \"search_attribute\", \"Number_of_search_word\",\"search_button_attribute_value\",\"is_button\", \"sClass\", \"URL name\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"SearchList_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"SearchList_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d458e",
   "metadata": {},
   "source": [
    "### Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b030e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pageListFunction(_url_):\n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    divPageList, navPageList,liPageList,ulPageList,spanPageList, sectionPageList, buttonPageList, \\\n",
    "    trPageList, footerPageList, aPageList, paginationPageList, bPageList \\\n",
    "    = soup.findAll('div',{\"data-attribute\":\"page\"}), soup.findAll('nav',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('li',{\"data-attribute\":\"page\"}), soup.findAll('ul',{\"data-attribute\":\"page\"}),\\\n",
    "    soup.findAll('span',{\"data-attribute\":\"page\"}), soup.findAll('section',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('button',{\"data-attribute\":\"page\"}), soup.findAll('tr',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('footer',{\"data-attribute\":\"page\"}), soup.findAll('a',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('pagination',{\"data-attribute\":\"page\"}), soup.findAll('b',{\"data-attribute\":\"page\"})\n",
    "    \n",
    "    try:\n",
    "        if divPageList != []:    \n",
    "            d_url_, d_NumOfButton, d_NumOfLinks, d_commonURL, d_NumberOfValues, d_page_attribute, d_PageListClass = pageList_Extract(soup, 'div',_url_)\n",
    "            return d_url_, d_NumOfButton, d_NumOfLinks, d_commonURL, d_NumberOfValues, d_page_attribute, d_PageListClass\n",
    "        \n",
    "        if navPageList != []:    \n",
    "            n_url_, n_NumOfButton, n_NumOfLinks, n_commonURL, n_NumberOfValues, n_page_attribute, n_PageListClass = pageList_Extract(soup, 'nav',_url_)\n",
    "            return n_url_, n_NumOfButton, n_NumOfLinks, n_commonURL, n_NumberOfValues, n_page_attribute, n_PageListClass\n",
    "        \n",
    "        if liPageList != []: \n",
    "            l_url_, l_NumOfButton, l_NumOfLinks, l_commonURL, l_NumberOfValues, l_page_attribute, l_PageListClass = pageList_Extract(soup, 'li',_url_)\n",
    "            return l_url_, l_NumOfButton, l_NumOfLinks, l_commonURL, l_NumberOfValues, l_page_attribute, l_PageListClass\n",
    "        \n",
    "        if ulPageList != []: \n",
    "            u_url_, u_NumOfButton, u_NumOfLinks, u_commonURL, u_NumberOfValues, u_page_attribute, u_PageListClass = pageList_Extract(soup, 'ul',_url_)\n",
    "            return u_url_, u_NumOfButton, u_NumOfLinks, u_commonURL, u_NumberOfValues, u_page_attribute, u_PageListClass\n",
    "        \n",
    "        if spanPageList != []:  \n",
    "            span_url_, span_NumOfButton, span_NumOfLinks, span_commonURL, span_NumberOfValues, span_page_attribute, span_PageListClass = pageList_Extract(soup, 'span',_url_)\n",
    "            return span_url_, span_NumOfButton, span_NumOfLinks, span_commonURL, span_NumberOfValues, span_page_attribute, span_PageListClass\n",
    "        \n",
    "        if sectionPageList != []: \n",
    "            sec_url_, sec_NumOfButton, sec_NumOfLinks, sec_commonURL, sec_NumberOfValues, sec_page_attribute, sec_PageListClass = pageList_Extract(soup, 'section',_url_) \n",
    "            return sec_url_, sec_NumOfButton, sec_NumOfLinks, sec_commonURL, sec_NumberOfValues, sec_page_attribute, sec_PageListClass \n",
    "        \n",
    "        if buttonPageList != []: \n",
    "            btn_url_, btn_NumOfButton, btn_NumOfLinks, btn_commonURL, btn_NumberOfValues, btn_page_attribute, btn_PageListClass = pageList_Extract(soup, 'button',_url_) \n",
    "            return btn_url_, btn_NumOfButton, btn_NumOfLinks, btn_commonURL, btn_NumberOfValues, btn_page_attribute, btn_PageListClass\n",
    "        \n",
    "        if trPageList != []: \n",
    "            tr_url_, tr_NumOfButton, tr_NumOfLinks, tr_commonURL, tr_NumberOfValues, tr_page_attribute, tr_PageListClass = pageList_Extract(soup, 'tr',_url_) \n",
    "            return tr_url_, tr_NumOfButton, tr_NumOfLinks, tr_commonURL, tr_NumberOfValues, tr_page_attribute, tr_PageListClass\n",
    "        \n",
    "        if footerPageList != []: \n",
    "            ft_url_, ft_NumOfButton, ft_NumOfLinks, ft_commonURL, ft_NumberOfValues, ft_page_attribute, ft_PageListClass = pageList_Extract(soup, 'footer',_url_) \n",
    "            return ft_url_, ft_NumOfButton, ft_NumOfLinks, ft_commonURL, ft_NumberOfValues, ft_page_attribute, ft_PageListClass \n",
    "        \n",
    "        if aPageList != []: \n",
    "            a_url_, a_NumOfButton, a_NumOfLinks, a_commonURL, a_NumberOfValues, a_page_attribute, a_PageListClass = pageList_Extract(soup, 'a',_url_) \n",
    "            return a_url_, a_NumOfButton, a_NumOfLinks, a_commonURL, a_NumberOfValues, a_page_attribute, a_PageListClass\n",
    "        \n",
    "        if paginationPageList != []: \n",
    "            pg_url_, pg_NumOfButton, pg_NumOfLinks, pg_commonURL, pg_NumberOfValues, pg_page_attribute, pg_PageListClass = pageList_Extract(soup, 'pagination',_url_) \n",
    "            return pg_url_, pg_NumOfButton, pg_NumOfLinks, pg_commonURL, pg_NumberOfValues, pg_page_attribute, pg_PageListClass\n",
    "        \n",
    "        if bPageList != []: \n",
    "            b_url_, b_NumOfButton, b_NumOfLinks, b_commonURL,  b_NumberOfValues, b_page_attribute, b_PageListClass = pageList_Extract(soup, 'b',_url_)  \n",
    "            return  b_url_, b_NumOfButton, b_NumOfLinks, b_commonURL,  b_NumberOfValues, b_page_attribute, b_PageListClass\n",
    "        else:\n",
    "            return _url_,\"0\",\"0\",\"0\",\"0\",\"0\",\"1\"\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def search(myDict, search1):\n",
    "    search.a=[]\n",
    "    for key, value in myDict.items():\n",
    "        if search1 in value:\n",
    "            search.a.append(key)\n",
    "    return len(search.a)\n",
    "\n",
    "def pageList_Extract(soup, tag,_url_):  \n",
    "    pageClass, NumOfPage, pageListAttribute, is_page, NumOfButton, NumOfLinks, NumberOfValues, outsideURL, insideURL, commonURL \\\n",
    "    = [] ,[], [],[], [], [], [], [], [], []\n",
    "    count, btn, valueCounter = 0, 0, 0\n",
    "    print(\"Tag: \", tag)\n",
    "    for ele in soup.findAll(tag):\n",
    "        try:\n",
    "            if \"data-attribute\" in list(ele.attrs.keys()) and \"page\" in list(ele.attrs.values()):\n",
    "                #print(ele)\n",
    "                nText = ele.text\n",
    "                #=======================Page Class======================= \n",
    "                pageClass.append(1)\n",
    "                #=======================Page Name======================= \n",
    "                is_present = bool(re.search('page', str(ele)) or re.search('show', str(ele)))\n",
    "                if(is_present == True):\n",
    "                    is_page.append(1)\n",
    "                else:\n",
    "                    is_page.append(0)\n",
    "                #====================Number of links==================== \n",
    "                for link in ele.find_all('a'):\n",
    "                    count += 1\n",
    "                NumOfLinks.append(count)\n",
    "                #====================Number of Button==================== \n",
    "                for btnlink in ele.find_all('button'):\n",
    "                    btn += 1\n",
    "                NumOfButton.append(btn)\n",
    "                #=======================Common url=======================\n",
    "                for link in ele.find_all('a'):\n",
    "                    insideURL.append(link.get('href'))\n",
    "                \n",
    "                for link in soup.find_all('a'):\n",
    "                    outsideURL.append(link.get('href'))\n",
    "\n",
    "                s = set(insideURL)\n",
    "                temp3 = [x for x in outsideURL if x not in s]\n",
    "                commonURL.append(len(outsideURL)-len(temp3))\n",
    "                \n",
    "                #=====================Number of values=====================\n",
    "                for link in ele.find_all('a'):\n",
    "                    if (link.text).isdigit()==True:\n",
    "                        valueCounter += 1\n",
    "                NumberOfValues.append(valueCounter)\n",
    "                #print(valueCounter)\n",
    "                    \n",
    "            else:\n",
    "                pageClass.append(0)\n",
    "                is_page.append(0)\n",
    "                NumOfButton.append(0)\n",
    "                NumOfLinks.append(0)\n",
    "                commonURL.append(0)\n",
    "                NumberOfValues.append(0)\n",
    "        except:\n",
    "                is_page.append(0)\n",
    "                NumOfButton.append(0)\n",
    "                NumOfLinks.append(0)\n",
    "                commonURL.append(0)\n",
    "                NumberOfValues.append(0)\n",
    "    \n",
    "    name_url = len(pageClass)*[_url_]\n",
    "    if (NumOfLinks ==[] or NumOfLinks is None):\n",
    "        NumOfLinks = [0]\n",
    "    if (NumOfButton ==[] or NumOfButton is None):\n",
    "        NumOfButton = [0] \n",
    "    if (commonURL ==[] or commonURL is None):\n",
    "        commonURL = [0] \n",
    "    if (pageClass == [] or pageClass is None):\n",
    "        pageClass = [1]\n",
    "    if (is_page == [] or is_page is None):\n",
    "        is_page = [0]\n",
    "    if (NumberOfValues == [] or NumberOfValues is None):\n",
    "        NumberOfValues = [0]\n",
    "    #print(len(name_url), len(NumOfButton), len(NumOfLinks), len(commonURL), len(is_page), len(pageClass))     \n",
    "    return name_url, NumOfButton, NumOfLinks, commonURL, NumberOfValues, is_page, pageClass\n",
    "\n",
    "def get_class_data(searchQ) :\n",
    "        start_time= time.time()\n",
    "        name_url, NumOfButton, NumOfLinks, commonURL,NumberOfValues, is_page, pageClass = pageListFunction(searchQ)\n",
    "        #checkBoxList = str(checkBoxList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #insideList = str(insideList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #filterClass = str(filterClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in NumOfButton:\n",
    "            NumOfButton = i\n",
    "            temp.append([NumOfButton])        \n",
    "        \n",
    "        t_NumOfLinks= []\n",
    "        for m in NumOfLinks:\n",
    "            t_NumOfLinks.append(m)\n",
    "        NumOfLinks_arr2d = np.matrix(temp)\n",
    "        NumOfLinks_to_add = np.array(t_NumOfLinks)\n",
    "        output_NumOfLinks = np.column_stack((NumOfLinks_arr2d, NumOfLinks_to_add))\n",
    "        f_NumOfLinks = output_NumOfLinks.tolist()\n",
    "        \n",
    "        t_commonURL = []\n",
    "        for m in commonURL:\n",
    "            t_commonURL.append(m)\n",
    "        commonURL_arr2d = np.matrix(f_NumOfLinks)\n",
    "        commonURL_to_add = np.array(t_commonURL)\n",
    "        output_commonURL = np.column_stack((commonURL_arr2d, commonURL_to_add))\n",
    "        f_commonURL = output_commonURL.tolist()\n",
    "        \n",
    "        t_is_Page = []\n",
    "        for m in is_page:\n",
    "            t_is_Page.append(m)\n",
    "        is_Page_arr2d = np.matrix(f_commonURL)\n",
    "        is_Page_to_add = np.array(t_is_Page)\n",
    "        output_is_Page = np.column_stack((is_Page_arr2d, is_Page_to_add))\n",
    "        f_is_Page = output_is_Page.tolist()\n",
    "        \n",
    "        t_NumberOfValues = []\n",
    "        for m in NumberOfValues:\n",
    "            t_NumberOfValues.append(m)\n",
    "        NumberOfValues_arr2d = np.matrix(f_is_Page)\n",
    "        NumberOfValues_to_add = np.array(t_NumberOfValues)\n",
    "        output_NumberOfValues = np.column_stack((NumberOfValues_arr2d, NumberOfValues_to_add))\n",
    "        f_NumberOfValues = output_NumberOfValues.tolist()\n",
    "        \n",
    "        t_pageClass = []\n",
    "        for m in pageClass:\n",
    "            t_pageClass.append(m)\n",
    "        pageClass_arr2d = np.matrix(f_NumberOfValues)\n",
    "        pageClass_to_add = np.array(t_pageClass)\n",
    "        output_pageClass = np.column_stack((pageClass_arr2d, pageClass_to_add))\n",
    "        f_pageClass = output_pageClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_pageClass)\n",
    "        column_name = np.array(name_url)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        hours, rem = divmod(end-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"\\nTime takes: {:0>2}:{:0>2}:{:05.2f} Seconds\\n\".format(int(hours),int(minutes),seconds))\n",
    "        return f_name\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"NumOfButton\", \"NumOfLinks\", \"commonURL\",\"is_page\", \"NumberOfValues\",\"pageClass\", \"name_url\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"pageList_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"pageList_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"rows!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a54bb",
   "metadata": {},
   "source": [
    "### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e903942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No UL\n",
      "No Select\n",
      "[ 2 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 3 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 29 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 30 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 31 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 32 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 33 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 34 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 35 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 36 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 37 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 38 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 39 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 40 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 41 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 42 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 43 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 44 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 45 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 46 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 47 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 48 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 49 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 50 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 51 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 104 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 105 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 106 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 107 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 110 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 149 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 150 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 151 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 152 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 153 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 235 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 236 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 237 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 238 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 239 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 361 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 362 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 371 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 372 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 373 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 374 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 383 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 384 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 518 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 519 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 520 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 521 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 522 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 523 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 581 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 582 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 583 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 584 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 585 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 586 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 587 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 588 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 589 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 590 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 591 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 592 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 593 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 594 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 595 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 596 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 597 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 598 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 707 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 708 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 709 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 710 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 711 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 712 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 713 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 714 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 715 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 716 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 717 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 718 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 719 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 858 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 878 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 879 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 906 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 907 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 908 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 909 ]. form!\n",
      "None\n",
      "UL\n",
      "No Select\n",
      "[ 963 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 964 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 969 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 970 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 971 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 972 ]. form!\n",
      "None\n",
      "No UL\n",
      "No Select\n",
      "[ 973 ]. form!\n",
      "None\n",
      "No UL\n",
      "Select\n",
      "[ 974 ]. form!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def sortFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    \n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    selectSearch = soup.findAll('select',{\"data-attribute\":\"sort\"})\n",
    "    ulSearch = soup.findAll('ul',{\"data-attribute\":\"sort\"})\n",
    "    '''\n",
    "    divSearch = soup.findAll('div',{\"data-attribute\":\"sort\"})\n",
    "    if not divSearch:\n",
    "        print(\"No Div\")\n",
    "    else:\n",
    "        print(\"Div\")\n",
    "    '''\n",
    "    if not ulSearch:\n",
    "        print(\"No UL\")\n",
    "    else:\n",
    "        print(\"UL\") \n",
    "    if not selectSearch:\n",
    "        print(\"No Select\")\n",
    "    else:\n",
    "        print(\"Select\")  \n",
    "    #print(soup.findAll(text=re.compile('^Sort By$')))\n",
    "    #print(len(soup.findAll(text=re.compile(\".*sort .*\"))))\n",
    "\n",
    "    if selectSearch != []:\n",
    "        #print(\"Select\")\n",
    "        for tests in soup.findAll('select'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()):\n",
    "                if \"sort\" in list(tests.attrs.values()):\n",
    "                    sortClass.append(1)\n",
    "                else:\n",
    "                    sortClass.append(0)\n",
    "            else:\n",
    "                sortClass.append(0)\n",
    "            if \" \" == tests.text:\n",
    "                sort_inner.append(0)             \n",
    "            else:\n",
    "                #print(tests.text)\n",
    "                if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                    #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                    sort_inner.append(1)\n",
    "                else:\n",
    "                    sort_inner.append(0)             \n",
    "            if('sort' in list(tests.attrs.values())):\n",
    "                #print(tests.attrs.values())\n",
    "                sort_attribute.append(1)\n",
    "            else:\n",
    "                sort_attribute.append(0) \n",
    "            optionTag = tests.findAll(\"option\")\n",
    "            option_tag_attribute_value.append(len(optionTag))\n",
    "    elif ulSearch != []:\n",
    "        #print(\"UL\")\n",
    "        for tests in soup.findAll('ul'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()):\n",
    "                if \"sort\" in list(tests.attrs.values()):\n",
    "                    sortClass.append(1)\n",
    "                else:\n",
    "                    sortClass.append(0)\n",
    "            else:\n",
    "                sortClass.append(0)\n",
    "            if \" \" == tests.text:\n",
    "                sort_inner.append(0)             \n",
    "            else:\n",
    "                #print(tests.text)\n",
    "                if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                    #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                    sort_inner.append(1)\n",
    "                else:\n",
    "                    sort_inner.append(0)             \n",
    "            if('sort' in list(tests.attrs.values())):\n",
    "                #print(tests.attrs.values())\n",
    "                sort_attribute.append(1)\n",
    "            else:\n",
    "                sort_attribute.append(0) \n",
    "            optionTag = tests.findAll(\"li\")\n",
    "            option_tag_attribute_value.append(len(optionTag))\n",
    "    else:\n",
    "        sortClass.append(0)\n",
    "        sort_inner.append(0)\n",
    "        option_tag_attribute_value.append(0)\n",
    "        sort_attribute.append(0)\n",
    "    if (sort_inner ==[]):\n",
    "        sort_inner = [0]\n",
    "    if (sort_attribute ==[]):\n",
    "        sort_attribute = [0]\n",
    "    if (option_tag_attribute_value ==[]):\n",
    "        option_tag_attribute_value = [0]\n",
    "    if (sortClass ==[]):\n",
    "        sortClass = [0]\n",
    "    if (t_count ==[]):\n",
    "        t_count = [0]    \n",
    "    temp = len(sort_inner)*[_url_]\n",
    "    \n",
    "    return temp, sort_inner,  option_tag_attribute_value, sort_attribute, sortClass,t_count\n",
    "\n",
    "def get_class_data(searchQ) :\n",
    "        name_url, sort_inner, option_tag_attribute_value, sort_attribute, sortClass, textCount = sortFunc(searchQ)\n",
    "        sort_inner = str(sort_inner)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        sort_attribute = str(sort_attribute)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #option_tag_attribute_value = str(option_tag_attribute_value)[1:-1]\n",
    "        sortClass = str(sortClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in sort_inner:\n",
    "            sort_inner = i\n",
    "            temp.append([sort_inner])        \n",
    "        \n",
    "        t_sort_attribute = []\n",
    "        for m in sort_attribute:\n",
    "            t_sort_attribute.append(m)\n",
    "        arr2d = np.matrix(temp)\n",
    "        column_to_add = np.array(t_sort_attribute)\n",
    "        output = np.column_stack((arr2d, column_to_add))\n",
    "        f_sort_attribute = output.tolist()\n",
    "        \n",
    "        t_option = []\n",
    "        for m in option_tag_attribute_value:\n",
    "            t_option.append(m)\n",
    "        option_arr2d = np.matrix(f_sort_attribute)\n",
    "        option_to_add = np.array(t_option)\n",
    "        output_option = np.column_stack((option_arr2d, option_to_add))\n",
    "        f_option = output_option.tolist()\n",
    "\n",
    "        t_sortClass = []\n",
    "        for m in sortClass:\n",
    "            t_sortClass.append(m)\n",
    "        sortClass_arr2d = np.matrix(f_option)\n",
    "        sortClass_add = np.array(t_sortClass)\n",
    "        sortClass_output = np.column_stack((sortClass_arr2d, sortClass_add))\n",
    "        f_sortClass = sortClass_output.tolist()\n",
    "        \n",
    "        t_textCount = []\n",
    "        for m in textCount:\n",
    "            t_textCount.append(m)\n",
    "        textCount_arr2d = np.matrix(f_sortClass)\n",
    "        textCount_add = np.array(t_textCount)\n",
    "        textCount_output = np.column_stack((textCount_arr2d, textCount_add))\n",
    "        f_textCount = textCount_output.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_textCount)\n",
    "        column_name = np.array(t_name)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "\n",
    "        return f_name\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"sort_inner\", \"sort_attribute\", \"option_tag_attribute_value\",\"sortClass\",\"textCount\",\"name_url\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"sort_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"sort_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a7606",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    divFilter, ulFilter, liFilter, formFilter, sectionFilter, fieldsetFilter, dtFilter,\\\n",
    "    buttonFilter,articleFilter,dlFilter,desktopfacetFilter = \\\n",
    "    soup.findAll('div',{\"data-attribute\":\"filter\"}),soup.findAll('ul',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('li',{\"data-attribute\":\"filter\"}), soup.findAll('form',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('section',{\"data-attribute\":\"filter\"}), soup.findAll('fieldset',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('dt',{\"data-attribute\":\"filter\"}),soup.findAll('button',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('article',{\"data-attribute\":\"filter\"}), soup.findAll('dl',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('desktop-facet',{\"data-attribute\":\"filter\"})\n",
    "    try:\n",
    "        if divFilter != []:    \n",
    "            div_name_url, div_checkBoxList, div_NumberOfLink, div_NumberOfInput, div_URL_List, div_button_List, div_filterClass = filter_Extract(soup, 'div',_url_)\n",
    "            return div_name_url, div_checkBoxList, div_NumberOfLink, div_NumberOfInput, div_URL_List, div_button_List, div_filterClass\n",
    "        if liFilter != []:    \n",
    "            li_name_url,  li_checkBoxList,  li_NumberOfLink,  li_NumberOfInput,  li_URL_List, li_button_List, li_filterClass = filter_Extract(soup, 'li',_url_)\n",
    "            return li_name_url,  li_checkBoxList,  li_NumberOfLink,  li_NumberOfInput, li_URL_List, li_button_List, li_filterClass\n",
    "        if buttonFilter != []:    \n",
    "            button_name_url, button_checkBoxList, button_NumberOfLink, button_NumberOfInput, button_URL_List, button_button_List, button_filterClass = filter_Extract(soup, 'button',_url_)\n",
    "            return button_name_url, button_checkBoxList, button_NumberOfLink, button_NumberOfInput, button_URL_List, button_button_List, button_filterClass\n",
    "        if dlFilter != []:    \n",
    "            dl_name_url, dl_checkBoxList, dl_NumberOfLink, dl_NumberOfInput, dl_URL_List, dl_button_List, dl_filterClass = filter_Extract(soup, 'dl',_url_)\n",
    "            return dl_name_url, dl_checkBoxList, dl_NumberOfLink, dl_NumberOfInput, dl_URL_List, dl_button_List, dl_filterClass \n",
    "        if desktopfacetFilter != []:    \n",
    "            df_name_url, df_checkBoxList, df_NumberOfLink, df_NumberOfInput, df_URL_List, df_button_List, df_filterClass = filter_Extract(soup, 'desktop-facet',_url_)\n",
    "            return df_name_url, df_checkBoxList, df_NumberOfLink, df_NumberOfInput, df_URL_List, df_button_List, df_filterClass\n",
    "        if articleFilter != []:    \n",
    "            art_name_url, art_checkBoxList, art_NumberOfLink, art_NumberOfInput, art_URL_List, art_button_List, art_filterClass = filter_Extract(soup, 'article',_url_)\n",
    "            return art_name_url, art_checkBoxList, art_NumberOfLink, art_NumberOfInput, art_URL_List, art_button_List, art_filterClass\n",
    "        if dtFilter != []:    \n",
    "            dt_name_url, dt_checkBoxList, dt_NumberOfLink, dt_NumberOfInput, dt_URL_List, dt_button_List, dt_filterClass = filter_Extract(soup, 'dt',_url_)\n",
    "            return dt_name_url, dt_checkBoxList, dt_NumberOfLink, dt_NumberOfInput, dt_URL_List, dt_button_List, dt_filterClass \n",
    "        if fieldsetFilter != []:    \n",
    "            f_name_url, f_checkBoxList, f_NumberOfLink, f_NumberOfInput, f_URL_List, f_button_List, f_filterClass = filter_Extract(soup, 'fieldset',_url_)\n",
    "            return f_name_url, f_checkBoxList, f_NumberOfLink, f_NumberOfInput, f_URL_List, f_button_List, f_filterClass\n",
    "        if sectionFilter != []:    \n",
    "            s_name_url, s_checkBoxList, s_NumberOfLink, s_NumberOfInput, s_URL_List, s_button_List, s_filterClass = filter_Extract(soup, 'section',_url_)\n",
    "            return s_name_url, s_checkBoxList, s_NumberOfLink, s_NumberOfInput, s_URL_List, s_button_List, s_filterClass\n",
    "        if formFilter != []:    \n",
    "            form_name_url, form_checkBoxList, form_NumberOfLink, form_NumberOfInput, form_URL_List, form_button_List, form_filterClass = filter_Extract(soup, 'form',_url_)\n",
    "            return form_name_url, form_checkBoxList, form_NumberOfLink, form_NumberOfInput, form_URL_List, form_button_List, form_filterClass\n",
    "        if ulFilter != []:    \n",
    "            ul_name_url, ul_checkBoxList, ul_NumberOfLink, ul_NumberOfInput, ul_URL_List, ul_button_List, ul_filterClass = filter_Extract(soup, 'ul',_url_)\n",
    "            return ul_name_url, ul_checkBoxList, ul_NumberOfLink, ul_NumberOfInput, ul_URL_List, ul_button_List, ul_filterClass\n",
    "        else:\n",
    "            return _url_,\"0\",\"0\",\"0\",\"0\",\"0\",\"1\"\n",
    "    except:\n",
    "        pass\n",
    "def filter_Extract(soup, tag,_url_):\n",
    "    fCount  = 0\n",
    "    filterClass, checkBoxList,insideList,outerList, NumberOfFilter, NumberOfLink, temp2,\\\n",
    "    NumberOfInput, URL_List, button_List = [], [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    for ele in soup.findAll(tag):\n",
    "                if \"data-attribute\" in list(ele.attrs.keys()) and \"filter\" in list(ele.attrs.values()):\n",
    "                        #======================= filterClass =======================\n",
    "                        filterClass.append(1)\n",
    "                        fCount +=1\n",
    "                        ch1 = 0\n",
    "                       \n",
    "                        #======================= Sub-Category ======================= \n",
    "                        child = 0\n",
    "                        for scat in ele.findAll('label'):\n",
    "                            child +=1\n",
    "                            #print(scat.text)\n",
    "                        insideList.append(child)\n",
    "                        #========================= CheckBox =========================             \n",
    "                        for chk in ele.findAll('input', {\"type\": \"checkbox\"}):\n",
    "                            pass\n",
    "                            ch1 += 1\n",
    "                        if ch1 !=0 and ch1 !=1:\n",
    "                            pass\n",
    "                            #print(ch1)\n",
    "                            checkBoxList.append(1)\n",
    "                        elif ch1 is None:\n",
    "                            pass\n",
    "                            #print(\"Empty\")\n",
    "                        else:\n",
    "                            checkBoxList.append(0)\n",
    "                      \n",
    "                        #=================== Number of link used =================== \n",
    "                        valueCounter =0\n",
    "                        for link in ele.findAll('a'):\n",
    "                            valueCounter += 1\n",
    "                        NumberOfLink.append(valueCounter)\n",
    "                        #=================== Number of inputbox =================== \n",
    "                        inputCounter = 0\n",
    "                        for link in ele.findAll('input'):\n",
    "                            inputCounter += 1\n",
    "                        NumberOfInput.append(inputCounter)\n",
    "                        #=================== Number of URL List =================== \n",
    "                        linkCount = 0\n",
    "                        for alink in ele.findAll('a', href=True):\n",
    "                            linkCount += 1\n",
    "                        URL_List.append(1)\n",
    "                        #=================== Number of button List =================== \n",
    "                        buttonCount = 0\n",
    "                        for btn in ele.findAll('button'):\n",
    "                            buttonCount += 1\n",
    "                        if buttonCount!=1:\n",
    "                            button_List.append(1)\n",
    "                        else:\n",
    "                            button_List.append(0)\n",
    "                else:\n",
    "                    filterClass.append(0)\n",
    "                    checkBoxList.append(0)  \n",
    "                    NumberOfLink.append(0)\n",
    "                    NumberOfInput.append(0)\n",
    "                    URL_List.append(0)\n",
    "                    button_List.append(0)\n",
    "\n",
    "    name_url = len(filterClass)*[_url_]\n",
    "    if (NumberOfLink ==[] or NumberOfLink is None):\n",
    "        NumberOfLink = [0]\n",
    "    if (NumberOfInput ==[] or NumberOfInput is None):\n",
    "        NumberOfInput = [0] \n",
    "    if (checkBoxList ==[] or checkBoxList is None):\n",
    "        checkBoxList = [0]\n",
    "    if (URL_List ==[] or URL_List is None):\n",
    "        URL_List = [0]\n",
    "    if (button_List ==[] or button_List is None):\n",
    "        button_List = [0]\n",
    "    if (filterClass == [] or filterClass is None):\n",
    "        filterClass = [1]\n",
    "    #print(len(filterClass))\n",
    "    #print(len(checkBoxList))\n",
    "    #print(len(NumberOfLink))\n",
    "    #print(len(NumberOfInput))\n",
    "    #print(len(URL_List))\n",
    "    #print(len(button_List))\n",
    "    return name_url, checkBoxList, NumberOfLink, NumberOfInput, URL_List, button_List, filterClass\n",
    "def get_class_data(searchQ) :\n",
    "        start_time= time.time()\n",
    "        name_url, checkBoxList, NumberOfLink, NumberOfInput, URL_List, button_List, filterClass = filterFunc(searchQ)\n",
    "        #checkBoxList = str(checkBoxList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #insideList = str(insideList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #filterClass = str(filterClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in checkBoxList:\n",
    "            checkBoxList = i\n",
    "            temp.append([checkBoxList])        \n",
    "        \n",
    "        t_NumberOfLink= []\n",
    "        for m in NumberOfLink:\n",
    "            t_NumberOfLink.append(m)\n",
    "        NumOfLinks_arr2d = np.matrix(temp)\n",
    "        NumOfLinks_to_add = np.array(t_NumberOfLink)\n",
    "        output_NumOfLinks = np.column_stack((NumOfLinks_arr2d, NumOfLinks_to_add))\n",
    "        f_NumOfLinks = output_NumOfLinks.tolist()\n",
    "        \n",
    "        t_NumberOfInput = []\n",
    "        for m in NumberOfInput:\n",
    "            t_NumberOfInput.append(m)\n",
    "        NumberOfInput_arr2d = np.matrix(f_NumOfLinks)\n",
    "        NumberOfInput_to_add = np.array(t_NumberOfInput)\n",
    "        output_NumberOfInput = np.column_stack((NumberOfInput_arr2d, NumberOfInput_to_add))\n",
    "        f_NumberOfInput = output_NumberOfInput.tolist()\n",
    "        \n",
    "        t_URL_List = []\n",
    "        for m in URL_List:\n",
    "            t_URL_List.append(m)\n",
    "        URL_List_arr2d = np.matrix(f_NumberOfInput)\n",
    "        URL_List_to_add = np.array(t_URL_List)\n",
    "        output_URL_List = np.column_stack((URL_List_arr2d, URL_List_to_add))\n",
    "        f_URL_List= output_URL_List.tolist()\n",
    "        \n",
    "        t_button_List = []\n",
    "        for m in button_List:\n",
    "            t_button_List.append(m)\n",
    "        button_List_arr2d = np.matrix(f_URL_List)\n",
    "        button_List_to_add = np.array(t_button_List)\n",
    "        output_button_List = np.column_stack((button_List_arr2d, button_List_to_add))\n",
    "        f_button_List= output_button_List.tolist()\n",
    "        \n",
    "        t_filterClass = []\n",
    "        for m in filterClass:\n",
    "            t_filterClass.append(m)\n",
    "        filterClass_arr2d = np.matrix(f_button_List)\n",
    "        filterClass_to_add = np.array(t_filterClass)\n",
    "        output_filterClass = np.column_stack((filterClass_arr2d, filterClass_to_add))\n",
    "        f_filterClass = output_filterClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_filterClass)\n",
    "        column_name = np.array(name_url)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        hours, rem = divmod(end-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"\\nTime takes: {:0>2}:{:0>2}:{:05.2f} Seconds\\n\".format(int(hours),int(minutes),seconds))\n",
    "        return f_name\n",
    "\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"checkBoxList\", \"NumberOfLink\",\"NumberOfInput\", \"URL_List\", \"button_List\",\"filterClass\", \"name_url\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"filter_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"filter_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea36b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/SearchList_test_set_1.csv'\n",
    "Search_csv_df = pd.read_csv(Search_searchpath)\n",
    "Search_X_test = Search_csv_df[[\"search_innertext\", \"search_attribute\", \"Number_of_search_word\",\"search_button_attribute_value\",\"is_button\"]]\n",
    "Search_y_test = Search_csv_df[[\"sClass\"]]\n",
    "searchname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/search_model.sav\"\n",
    "target_names = ['Non-Search', 'Search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6a18c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class 0 precision = 96.65\n",
      "Average class 1 precision = 39.53\n",
      "Average class 0 recall = 94.34\n",
      "Average class 1 recall = 53.12\n",
      "Accuracy: 91.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Search       0.97      0.94      0.95       459\n",
      "      Search       0.40      0.53      0.45        32\n",
      "\n",
      "    accuracy                           0.92       491\n",
      "   macro avg       0.68      0.74      0.70       491\n",
      "weighted avg       0.93      0.92      0.92       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluation(Search_X_test,Search_y_test,searchname,target_names):\n",
    "    p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "    searchname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/search_model.sav\"\n",
    "    search_model = pickle.load(open(searchname, 'rb'))\n",
    "    y_score = search_model.predict(Search_X_test)\n",
    "    precision = precision_score(Search_y_test, y_score, average=None)\n",
    "    p_class_0.append(precision[0])\n",
    "    p_class_1.append(precision[1])\n",
    "    recall = recall_score(Search_y_test, y_score, average=None)\n",
    "    r_class_0.append(recall[0])\n",
    "    r_class_1.append(recall[1])\n",
    "    print('Average class 0 precision = {:.2f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "    print('Average class 1 precision = {:.2f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "    print('Average class 0 recall = {:.2f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "    print('Average class 1 recall = {:.2f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "    print('Accuracy: {:.2f}'.format(accuracy_score(Search_y_test, y_score)*100))\n",
    "    \n",
    "    print(classification_report(Search_y_test, y_score, target_names=target_names))\n",
    "evaluation(Search_X_test,Search_y_test,searchname,target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a60d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class 0 precision = 99.77\n",
      "Average class 1 precision = 100.00\n",
      "Average class 0 recall = 100.00\n",
      "Average class 1 recall = 54.66\n",
      "Accuracy: 99.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Search       1.00      1.00      1.00    151373\n",
      "      Search       1.00      0.55      0.71       761\n",
      "\n",
      "    accuracy                           1.00    152134\n",
      "   macro avg       1.00      0.77      0.85    152134\n",
      "weighted avg       1.00      1.00      1.00    152134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/filter_test_set_1.csv'\n",
    "filter_csv_df = pd.read_csv(filter_searchpath)\n",
    "filter_X_test = filter_csv_df[[\"checkBoxList\", \"NumberOfLink\",\"NumberOfInput\", \"URL_List\", \"button_List\"]]\n",
    "filter_y_test = filter_csv_df[[\"filterClass\"]]\n",
    "filtername = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/filter_model.sav\"\n",
    "target_names = ['Non-Filter', 'Filter']\n",
    "evaluation(filter_X_test,filter_y_test,filtername,target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68a2e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class 0 precision = 100.00\n",
      "Average class 1 precision = 5.42\n",
      "Average class 0 recall = 63.38\n",
      "Average class 1 recall = 100.00\n",
      "Accuracy: 64.13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-sort       1.00      0.63      0.78       953\n",
      "        Sort       0.05      1.00      0.10        20\n",
      "\n",
      "    accuracy                           0.64       973\n",
      "   macro avg       0.53      0.82      0.44       973\n",
      "weighted avg       0.98      0.64      0.76       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sort_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/sort_test_set_1.csv'\n",
    "sort_csv_df = pd.read_csv(sort_searchpath)\n",
    "sort_X_test = sort_csv_df[['sort_inner','sort_attribute','option_tag_attribute_value','textCount']]\n",
    "\n",
    "sort_y_test = sort_csv_df[[\"sortClass\"]]\n",
    "\n",
    "sortname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/sort_model.sav\"\n",
    "\n",
    "\n",
    "target_names = ['Non-sort', 'Sort']\n",
    "evaluation(filter_X_test,filter_y_test,filtername,target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d52f1d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54762 entries, 0 to 54761\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   NumOfButton     54762 non-null  int64\n",
      " 1   NumOfLinks      54762 non-null  int64\n",
      " 2   commonURL       54762 non-null  int64\n",
      " 3   is_page         54762 non-null  int64\n",
      " 4   NumberOfValues  54762 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 2.1 MB\n",
      "None\n",
      "LogisticRegression(intercept_scaling=10000.0, penalty='l1', solver='liblinear',\n",
      "                   tol=1e-06, warm_start=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5 features per sample; expecting 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/sxpbd7294kg6s7m7cz0pcn6h0000gn/T/ipykernel_5080/1731914456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpagename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mp_class_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5 features per sample; expecting 7"
     ]
    }
   ],
   "source": [
    "page_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/pageList_test_set_1.csv'\n",
    "page_csv_df = pd.read_csv(page_searchpath)\n",
    "page_X_test = page_csv_df[['NumOfButton','NumOfLinks','commonURL','is_page','NumberOfValues']]\n",
    "page_y_test = page_csv_df[[\"pageClass\"]]\n",
    "pagename = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/page_model.sav\"\n",
    "print(page_X_test.info())\n",
    "\n",
    "p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "page_model = pickle.load(open(pagename, 'rb'))\n",
    "print(page_model)\n",
    "y_score = page_model.predict(page_X_test)\n",
    "precision = precision_score(page_y_test, y_score, average=None)\n",
    "p_class_0.append(precision[0])\n",
    "p_class_1.append(precision[1])\n",
    "recall = recall_score(page_y_test, y_score, average=None)\n",
    "r_class_0.append(recall[0])\n",
    "r_class_1.append(recall[1])\n",
    "print('Average class 0 precision = {:.2f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "print('Average class 1 precision = {:.2f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "print('Average class 0 recall = {:.2f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "print('Average class 1 recall = {:.2f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(page_y_test, y_score)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b9a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
