{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde454bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "from testURL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107dfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/mdjavedulferdous/Documents/Dataset/Testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875b22e",
   "metadata": {},
   "source": [
    "### Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778128aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init import *\n",
    "from allURL import *\n",
    "\n",
    "def search(myDict, search1):\n",
    "    search.a=[]\n",
    "    for key, value in myDict.items():\n",
    "        if search1 in value:\n",
    "            search.a.append(key)\n",
    "    return len(search.a)\n",
    "\n",
    "def search_query(_url_):\n",
    "    s_inner,is_button,search_attribute, noWord, sClass,search_button_attribute_value  = ([] for i in range(6)) \n",
    "    BnoWord = 0\n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    #print(soup)\n",
    "    try:\n",
    "        for tests in soup.findAll('form'):\n",
    "            my_attributes = tests.attrs\n",
    "            #print(my_attributes)\n",
    "            if \"data-attribute\" in list(my_attributes.keys()):\n",
    "                if \"search\" in list(my_attributes.values()):\n",
    "                    sClass.append(1)\n",
    "                else:\n",
    "                    sClass.append(0)\n",
    "            else:\n",
    "                sClass.append(0)\n",
    "            if('search' in list(tests.attrs.values())):\n",
    "                search_attribute.append(1)\n",
    "            else:\n",
    "                search_attribute.append(0) \n",
    "            if \" \" == tests.text:\n",
    "                s_inner.append(0)\n",
    "                \n",
    "            else:\n",
    "                s_inner.append(1)                \n",
    "            my_no = tests.attrs\n",
    "            noWord.append(search(my_no, \"search\"))\n",
    "            \n",
    "            is_present = bool(re.search('button', str(tests)))\n",
    "            if(is_present == True):\n",
    "                is_button.append(1)\n",
    "            else:\n",
    "                is_button.append(0)\n",
    "                \n",
    "            if \"data-attribute\" in list(my_attributes.keys()):    \n",
    "                buttonSearch = tests.find(\"button\")\n",
    "                button_attributes = buttonSearch.attrs\n",
    "                BnoWord = search(button_attributes, \"search\")\n",
    "                if(BnoWord == 1):\n",
    "                    search_button_attribute_value.append(1)\n",
    "                else:\n",
    "                    search_button_attribute_value.append(0)\n",
    "            else:\n",
    "                search_button_attribute_value.append(0)\n",
    "            \n",
    "    except:\n",
    "        search_button_attribute_value.append(0)\n",
    "    \n",
    "    if (s_inner ==[]):\n",
    "        s_inner = [0]\n",
    "    if (search_attribute ==[]):\n",
    "        search_attribute = [0]\n",
    "    if (noWord ==[]):\n",
    "        noWord = [0]\n",
    "    if (is_button ==[]):\n",
    "        is_button = [0]\n",
    "    if (search_button_attribute_value ==[]):\n",
    "        search_button_attribute_value = [0]    \n",
    "    if (sClass ==[]):\n",
    "        sClass = [1]\n",
    "    \n",
    "    temp = len(s_inner)*[_url_]\n",
    "    \n",
    "    return temp,s_inner, search_attribute,noWord,is_button, search_button_attribute_value,sClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(searchQ) :\n",
    "        name_url, search_innertext,search_attribute,noWord, is_button, search_button_attribute_value, sClass = search_query(searchQ)\n",
    "        search_innertext = str(search_innertext)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        search_attribute = str(search_attribute)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        noWord = str(noWord)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        is_button = str(is_button)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        search_button_attribute_value = str(search_button_attribute_value)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        sClass = str(sClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        \n",
    "        for i in search_innertext:\n",
    "            search_innertext = i\n",
    "            temp.append([search_innertext])        \n",
    "            \n",
    "        t_search_attribute = []\n",
    "        for m in search_attribute:\n",
    "            t_search_attribute.append(m)\n",
    "        arr2d = np.matrix(temp)\n",
    "        column_to_add = np.array(t_search_attribute)\n",
    "        output = np.column_stack((arr2d, column_to_add))\n",
    "        f_search_attribute = output.tolist()\n",
    "        \n",
    "        t_noWord = []\n",
    "        for m in noWord:\n",
    "            t_noWord.append(m)\n",
    "        a_noWord = np.matrix(f_search_attribute)\n",
    "        column_noWord = np.array(t_noWord)\n",
    "        o_noWord = np.column_stack((a_noWord, column_noWord))\n",
    "        f_noWord = o_noWord.tolist()        \n",
    "        \n",
    "        t_is_button= []\n",
    "        for m in is_button:\n",
    "            t_is_button.append(m)\n",
    "        a_is_button = np.matrix(f_noWord)\n",
    "        column_is_button= np.array(t_is_button)\n",
    "        o_is_button = np.column_stack((a_is_button, column_is_button))\n",
    "        f_is_button= o_is_button.tolist()        \n",
    "        \n",
    "        t_s_value= []\n",
    "        for m in search_button_attribute_value:\n",
    "            t_s_value.append(m)\n",
    "        a_s_value = np.matrix(f_is_button)\n",
    "        column_s_value= np.array(t_s_value)\n",
    "        o_s_value = np.column_stack((a_s_value, column_s_value))\n",
    "        f_s_value= o_s_value.tolist()\n",
    "        \n",
    "        t_sClass= []\n",
    "        for m in sClass:\n",
    "            t_sClass.append(m)\n",
    "        a_sClass = np.matrix(f_s_value)\n",
    "        column_sClass= np.array(t_sClass)\n",
    "        o_sClass = np.column_stack((a_sClass, column_sClass))\n",
    "        f_sClass= o_sClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_sClass)\n",
    "        column_name = np.array(t_name)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        return f_name\n",
    "#get_class_data(url_104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5828c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header():\n",
    "    list_of_header = [\"search_innertext\", \"search_attribute\", \"Number_of_search_word\",\"search_button_attribute_value\",\"is_button\", \"sClass\", \"URL name\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"SearchList_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"SearchList_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d458e",
   "metadata": {},
   "source": [
    "### Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b030e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.35 Seconds\n",
      "\n",
      "[ 1220 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.86 Seconds\n",
      "\n",
      "[ 1221 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.47 Seconds\n",
      "\n",
      "[ 1222 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.28 Seconds\n",
      "\n",
      "[ 1223 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:00.31 Seconds\n",
      "\n",
      "[ 1233 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.83 Seconds\n",
      "\n",
      "[ 1234 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 1235 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 1660 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.54 Seconds\n",
      "\n",
      "[ 1883 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 2702 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 2726 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.93 Seconds\n",
      "\n",
      "[ 5673 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.59 Seconds\n",
      "\n",
      "[ 6261 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.57 Seconds\n",
      "\n",
      "[ 6262 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.06 Seconds\n",
      "\n",
      "[ 6263 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:01.03 Seconds\n",
      "\n",
      "[ 6550 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 6587 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.20 Seconds\n",
      "\n",
      "[ 6588 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 6589 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.34 Seconds\n",
      "\n",
      "[ 6986 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.35 Seconds\n",
      "\n",
      "[ 6987 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.15 Seconds\n",
      "\n",
      "[ 6988 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 7261 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 7868 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.80 Seconds\n",
      "\n",
      "[ 7869 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.41 Seconds\n",
      "\n",
      "[ 8197 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.66 Seconds\n",
      "\n",
      "[ 9099 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:02.01 Seconds\n",
      "\n",
      "[ 10303 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.95 Seconds\n",
      "\n",
      "[ 10304 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 10368 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.12 Seconds\n",
      "\n",
      "[ 10504 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.21 Seconds\n",
      "\n",
      "[ 10671 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.63 Seconds\n",
      "\n",
      "[ 11022 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 11953 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.89 Seconds\n",
      "\n",
      "[ 11954 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.41 Seconds\n",
      "\n",
      "[ 11955 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.69 Seconds\n",
      "\n",
      "[ 12374 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:02.00 Seconds\n",
      "\n",
      "[ 12375 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.25 Seconds\n",
      "\n",
      "[ 12520 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.20 Seconds\n",
      "\n",
      "[ 12521 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:01.46 Seconds\n",
      "\n",
      "[ 13444 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 13617 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.07 Seconds\n",
      "\n",
      "[ 13681 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.26 Seconds\n",
      "\n",
      "[ 14078 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.36 Seconds\n",
      "\n",
      "[ 14496 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 14497 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.29 Seconds\n",
      "\n",
      "[ 15455 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.52 Seconds\n",
      "\n",
      "[ 15456 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.53 Seconds\n",
      "\n",
      "[ 16901 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:00.23 Seconds\n",
      "\n",
      "[ 16972 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.39 Seconds\n",
      "\n",
      "[ 16973 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 17152 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.78 Seconds\n",
      "\n",
      "[ 18873 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:00.49 Seconds\n",
      "\n",
      "[ 18884 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.34 Seconds\n",
      "\n",
      "[ 19058 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.81 Seconds\n",
      "\n",
      "[ 20420 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.57 Seconds\n",
      "\n",
      "[ 21495 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.73 Seconds\n",
      "\n",
      "[ 21496 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.62 Seconds\n",
      "\n",
      "[ 21497 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.34 Seconds\n",
      "\n",
      "[ 21498 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.69 Seconds\n",
      "\n",
      "[ 21499 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.46 Seconds\n",
      "\n",
      "[ 23994 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 24353 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.41 Seconds\n",
      "\n",
      "[ 24853 ]. form!\n",
      "None\n",
      "Tag:  button\n",
      "\n",
      "Time takes: 00:00:01.04 Seconds\n",
      "\n",
      "[ 25125 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.55 Seconds\n",
      "\n",
      "[ 25126 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.40 Seconds\n",
      "\n",
      "[ 26451 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:01.19 Seconds\n",
      "\n",
      "[ 30402 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.82 Seconds\n",
      "\n",
      "[ 33988 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.44 Seconds\n",
      "\n",
      "[ 36302 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.66 Seconds\n",
      "\n",
      "[ 36303 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.20 Seconds\n",
      "\n",
      "[ 36720 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.35 Seconds\n",
      "\n",
      "[ 37071 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 37710 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.20 Seconds\n",
      "\n",
      "[ 37711 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.57 Seconds\n",
      "\n",
      "[ 38051 ]. form!\n",
      "None\n",
      "Tag:  a\n",
      "\n",
      "Time takes: 00:00:00.28 Seconds\n",
      "\n",
      "[ 38232 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.30 Seconds\n",
      "\n",
      "[ 38233 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.40 Seconds\n",
      "\n",
      "[ 38234 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.31 Seconds\n",
      "\n",
      "[ 38899 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.21 Seconds\n",
      "\n",
      "[ 39554 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.60 Seconds\n",
      "\n",
      "[ 39555 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:01.25 Seconds\n",
      "\n",
      "[ 40475 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.42 Seconds\n",
      "\n",
      "[ 40609 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.49 Seconds\n",
      "\n",
      "[ 42137 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.48 Seconds\n",
      "\n",
      "[ 42138 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:01.09 Seconds\n",
      "\n",
      "[ 45412 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.47 Seconds\n",
      "\n",
      "[ 46136 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.24 Seconds\n",
      "\n",
      "[ 46137 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.24 Seconds\n",
      "\n",
      "[ 48599 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.19 Seconds\n",
      "\n",
      "[ 48832 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:01.67 Seconds\n",
      "\n",
      "[ 48833 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:00.50 Seconds\n",
      "\n",
      "[ 49597 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.37 Seconds\n",
      "\n",
      "[ 49758 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.49 Seconds\n",
      "\n",
      "[ 49968 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.32 Seconds\n",
      "\n",
      "[ 49969 ]. form!\n",
      "None\n",
      "Tag:  li\n",
      "\n",
      "Time takes: 00:00:00.66 Seconds\n",
      "\n",
      "[ 50316 ]. form!\n",
      "None\n",
      "Tag:  div\n",
      "\n",
      "Time takes: 00:00:02.34 Seconds\n",
      "\n",
      "[ 54445 ]. form!\n",
      "None\n",
      "\n",
      "Time takes: 00:00:00.85 Seconds\n",
      "\n",
      "[ 54446 ]. form!\n",
      "None\n",
      "Tag:  span\n",
      "\n",
      "Time takes: 00:00:00.32 Seconds\n",
      "\n",
      "[ 54763 ]. form!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def pageListFunction(_url_):\n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    divPageList, navPageList,liPageList,ulPageList,spanPageList, sectionPageList, buttonPageList, \\\n",
    "    trPageList, footerPageList, aPageList, paginationPageList, bPageList \\\n",
    "    = soup.findAll('div',{\"data-attribute\":\"page\"}), soup.findAll('nav',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('li',{\"data-attribute\":\"page\"}), soup.findAll('ul',{\"data-attribute\":\"page\"}),\\\n",
    "    soup.findAll('span',{\"data-attribute\":\"page\"}), soup.findAll('section',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('button',{\"data-attribute\":\"page\"}), soup.findAll('tr',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('footer',{\"data-attribute\":\"page\"}), soup.findAll('a',{\"data-attribute\":\"page\"}), \\\n",
    "    soup.findAll('pagination',{\"data-attribute\":\"page\"}), soup.findAll('b',{\"data-attribute\":\"page\"})\n",
    "    \n",
    "    try:\n",
    "        if divPageList != []:    \n",
    "            d_url_, d_NumOfButton, d_NumOfLinks, d_commonURL, d_NumberOfValues, d_page_attribute, d_NumOfPage, d_navType, d_PageListClass = pageList_Extract(soup, 'div',_url_)\n",
    "            return d_url_, d_NumOfButton, d_NumOfLinks, d_commonURL, d_NumberOfValues, d_page_attribute, d_NumOfPage, d_navType, d_PageListClass\n",
    "        \n",
    "        if navPageList != []:    \n",
    "            n_url_, n_NumOfButton, n_NumOfLinks, n_commonURL, n_NumberOfValues, n_page_attribute, n_NumOfPage, n_navType, n_PageListClass = pageList_Extract(soup, 'nav',_url_)\n",
    "            return n_url_, n_NumOfButton, n_NumOfLinks, n_commonURL, n_NumberOfValues, n_page_attribute, n_NumOfPage, n_navType, n_PageListClass\n",
    "        \n",
    "        if liPageList != []: \n",
    "            l_url_, l_NumOfButton, l_NumOfLinks, l_commonURL, l_NumberOfValues, l_page_attribute, l_NumOfPage, l_navType, l_PageListClass = pageList_Extract(soup, 'li',_url_)\n",
    "            return l_url_, l_NumOfButton, l_NumOfLinks, l_commonURL, l_NumberOfValues, l_page_attribute, l_NumOfPage, l_navType, l_PageListClass\n",
    "        \n",
    "        if ulPageList != []: \n",
    "            u_url_, u_NumOfButton, u_NumOfLinks, u_commonURL, u_NumberOfValues, u_page_attribute, u_NumOfPage, u_navType, u_PageListClass = pageList_Extract(soup, 'ul',_url_)\n",
    "            return u_url_, u_NumOfButton, u_NumOfLinks, u_commonURL, u_NumberOfValues, u_page_attribute, u_NumOfPage, u_navType, u_PageListClass\n",
    "        \n",
    "        if spanPageList != []:  \n",
    "            span_url_, span_NumOfButton, span_NumOfLinks, span_commonURL, span_NumberOfValues, span_page_attribute, span_NumOfPage, span_navType, span_PageListClass = pageList_Extract(soup, 'span',_url_)\n",
    "            return span_url_, span_NumOfButton, span_NumOfLinks, span_commonURL, span_NumberOfValues, span_page_attribute, span_NumOfPage, span_navType, span_PageListClass\n",
    "        \n",
    "        if sectionPageList != []: \n",
    "            sec_url_, sec_NumOfButton, sec_NumOfLinks, sec_commonURL, sec_NumberOfValues, sec_page_attribute, sec_NumOfPage, sec_navType, sec_PageListClass = pageList_Extract(soup, 'section',_url_) \n",
    "            return sec_url_, sec_NumOfButton, sec_NumOfLinks, sec_commonURL, sec_NumberOfValues, sec_page_attribute, sec_NumOfPage, sec_navType, sec_PageListClass \n",
    "        \n",
    "        if buttonPageList != []: \n",
    "            btn_url_, btn_NumOfButton, btn_NumOfLinks, btn_commonURL, btn_NumberOfValues, btn_page_attribute, btn_NumOfPage, btn_navType, btn_PageListClass = pageList_Extract(soup, 'button',_url_) \n",
    "            return btn_url_, btn_NumOfButton, btn_NumOfLinks, btn_commonURL, btn_NumberOfValues, btn_page_attribute, btn_NumOfPage, btn_navType, btn_PageListClass\n",
    "        \n",
    "        if trPageList != []: \n",
    "            tr_url_, tr_NumOfButton, tr_NumOfLinks, tr_commonURL, tr_NumberOfValues, tr_page_attribute, tr_NumOfPage, tr_navType, tr_PageListClass = pageList_Extract(soup, 'tr',_url_) \n",
    "            return tr_url_, tr_NumOfButton, tr_NumOfLinks, tr_commonURL, tr_NumberOfValues, tr_page_attribute, tr_NumOfPage, tr_navType, tr_PageListClass\n",
    "        \n",
    "        if footerPageList != []: \n",
    "            ft_url_, ft_NumOfButton, ft_NumOfLinks, ft_commonURL, ft_NumberOfValues, ft_page_attribute, ft_NumOfPage, ft_navType, ft_PageListClass = pageList_Extract(soup, 'footer',_url_) \n",
    "            return ft_url_, ft_NumOfButton, ft_NumOfLinks, ft_commonURL, ft_NumberOfValues, ft_page_attribute, ft_NumOfPage, ft_navType, ft_PageListClass \n",
    "        \n",
    "        if aPageList != []: \n",
    "            a_url_, a_NumOfButton, a_NumOfLinks, a_commonURL, a_NumberOfValues, a_page_attribute, a_NumOfPage, a_navType, a_PageListClass = pageList_Extract(soup, 'a',_url_) \n",
    "            return a_url_, a_NumOfButton, a_NumOfLinks, a_commonURL, a_NumberOfValues, a_page_attribute, a_NumOfPage, a_navType, a_PageListClass\n",
    "        \n",
    "        if paginationPageList != []: \n",
    "            pg_url_, pg_NumOfButton, pg_NumOfLinks, pg_commonURL, pg_NumberOfValues, pg_page_attribute, pg_NumOfPage, pg_navType, pg_PageListClass = pageList_Extract(soup, 'pagination',_url_) \n",
    "            return pg_url_, pg_NumOfButton, pg_NumOfLinks, pg_commonURL, pg_NumberOfValues, pg_page_attribute, pg_NumOfPage, pg_navType, pg_PageListClass\n",
    "        \n",
    "        if bPageList != []: \n",
    "            b_url_, b_NumOfButton, b_NumOfLinks, b_commonURL,  b_NumberOfValues, b_page_attribute, b_NumOfPage, b_navType, b_PageListClass = pageList_Extract(soup, 'b',_url_)  \n",
    "            return  b_url_, b_NumOfButton, b_NumOfLinks, b_commonURL,  b_NumberOfValues, b_page_attribute, b_NumOfPage, b_navType, b_PageListClass\n",
    "        else:\n",
    "            return _url_,\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"1\"\n",
    "    except:\n",
    "        pass\n",
    "def search(myDict, search1):\n",
    "    search.a=[]\n",
    "    for key, value in myDict.items():\n",
    "        if search1 in value:\n",
    "            search.a.append(key)\n",
    "    return len(search.a)\n",
    "\n",
    "\n",
    "def pageList_Extract(soup, tag,_url_):  \n",
    "    pageClass, NumOfPage, pageListAttribute, is_page, NumOfButton, NumOfLinks, NumberOfValues, outsideURL, insideURL, commonURL, \\\n",
    "    navType= [] ,[], [],[], [], [], [], [], [], [], []\n",
    "    count, btn, valueCounter = 0, 0, 0\n",
    "    print(\"Tag: \", tag)\n",
    "    for ele in soup.findAll(tag):\n",
    "        try:\n",
    "            if \"data-attribute\" in list(ele.attrs.keys()) and \"page\" in list(ele.attrs.values()):\n",
    "                #print(ele)\n",
    "                nText = ele.text\n",
    "                #=======================Page Class======================= \n",
    "                pageClass.append(1)\n",
    "                #=======================Page Name======================= \n",
    "                is_present = bool(re.search('page', str(ele)) or re.search('show', str(ele)))\n",
    "                if(is_present == True):\n",
    "                    is_page.append(1)\n",
    "                else:\n",
    "                    is_page.append(0)\n",
    "                #====================Number of links==================== \n",
    "                for link in ele.find_all('a'):\n",
    "                    count += 1\n",
    "                NumOfLinks.append(count)\n",
    "                #====================Number of Button==================== \n",
    "                for btnlink in ele.find_all('button'):\n",
    "                    btn += 1\n",
    "                NumOfButton.append(btn)\n",
    "                #=======================Common url=======================\n",
    "                for link in ele.find_all('a'):\n",
    "                    insideURL.append(link.get('href'))\n",
    "                \n",
    "                for link in soup.find_all('a'):\n",
    "                    outsideURL.append(link.get('href'))\n",
    "\n",
    "                s = set(insideURL)\n",
    "                temp3 = [x for x in outsideURL if x not in s]\n",
    "                commonURL.append(len(outsideURL)-len(temp3))\n",
    "                \n",
    "                #=====================Number of values=====================\n",
    "                for link in ele.find_all('a'):\n",
    "                    if (link.text).isdigit()==True:\n",
    "                        valueCounter += 1\n",
    "                NumberOfValues.append(valueCounter)\n",
    "                #print(valueCounter)\n",
    "                \n",
    "                #=====================Number of pages=====================\n",
    "                temp1 = re.findall(r'\\d+', ele.text) \n",
    "                res2 = list(map(int, temp1))\n",
    "                NumOfPage.append(res2[-1])\n",
    "                #print(res2[-1])\n",
    "                #=====================Navigation type=====================\n",
    "                nav = ele.find('button')\n",
    "                alink = ele.find('a')\n",
    "                if (bool(nav)) == True:\n",
    "                    if(bool(alink)) == True and (bool(nav)) == True:\n",
    "                        navType.append(3)\n",
    "                    else:\n",
    "                        navType.append(1)\n",
    "                elif(bool(alink)) == True:\n",
    "                    navType.append(2)\n",
    "                else:\n",
    "                    navType.append(0)\n",
    "            else:\n",
    "                pageClass.append(0)\n",
    "                is_page.append(0)\n",
    "                NumOfButton.append(0)\n",
    "                NumOfLinks.append(0)\n",
    "                commonURL.append(0)\n",
    "                NumberOfValues.append(0)\n",
    "                NumOfPage.append(0)\n",
    "                navType.append(0)\n",
    "        except:\n",
    "                NumOfPage.append(0)\n",
    "                navType.append(0)\n",
    "                pass\n",
    "    \n",
    "    name_url = len(pageClass)*[_url_]\n",
    "    if (NumOfLinks ==[] or NumOfLinks is None):\n",
    "        NumOfLinks = [0]\n",
    "    if (NumOfButton ==[] or NumOfButton is None):\n",
    "        NumOfButton = [0] \n",
    "    if (commonURL ==[] or commonURL is None):\n",
    "        commonURL = [0] \n",
    "    if (pageClass == [] or pageClass is None):\n",
    "        pageClass = [1]\n",
    "    if (is_page == [] or is_page is None):\n",
    "        is_page = [0]    \n",
    "    if (NumOfPage == [] or NumOfPage is None):\n",
    "        NumOfPage = [0]\n",
    "    if (NumberOfValues == [] or NumberOfValues is None):\n",
    "        NumberOfValues = [0]\n",
    "    if (navType == [] or navType is None):\n",
    "        navType = [0]\n",
    "    #print(len(navType), len(name_url), len(NumOfButton), len(NumOfLinks), len(commonURL), len(is_page), len(pageClass), len(NumOfPage))     \n",
    "    return name_url, NumOfButton, NumOfLinks, commonURL, NumberOfValues, is_page, NumOfPage, navType, pageClass \n",
    "\n",
    "def get_class_data(searchQ) :\n",
    "        start_time= time.time()\n",
    "        name_url, NumOfButton, NumOfLinks, commonURL,NumberOfValues, is_page, NumOfPage, navType, pageClass = pageListFunction(searchQ)\n",
    "        #checkBoxList = str(checkBoxList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #insideList = str(insideList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #filterClass = str(filterClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in NumOfButton:\n",
    "            NumOfButton = i\n",
    "            temp.append([NumOfButton])        \n",
    "        \n",
    "        t_NumOfLinks= []\n",
    "        for m in NumOfLinks:\n",
    "            t_NumOfLinks.append(m)\n",
    "        NumOfLinks_arr2d = np.matrix(temp)\n",
    "        NumOfLinks_to_add = np.array(t_NumOfLinks)\n",
    "        output_NumOfLinks = np.column_stack((NumOfLinks_arr2d, NumOfLinks_to_add))\n",
    "        f_NumOfLinks = output_NumOfLinks.tolist()\n",
    "        \n",
    "        t_commonURL = []\n",
    "        for m in commonURL:\n",
    "            t_commonURL.append(m)\n",
    "        commonURL_arr2d = np.matrix(f_NumOfLinks)\n",
    "        commonURL_to_add = np.array(t_commonURL)\n",
    "        output_commonURL = np.column_stack((commonURL_arr2d, commonURL_to_add))\n",
    "        f_commonURL = output_commonURL.tolist()\n",
    "        \n",
    "        t_is_Page = []\n",
    "        for m in is_page:\n",
    "            t_is_Page.append(m)\n",
    "        is_Page_arr2d = np.matrix(f_commonURL)\n",
    "        is_Page_to_add = np.array(t_is_Page)\n",
    "        output_is_Page = np.column_stack((is_Page_arr2d, is_Page_to_add))\n",
    "        f_is_Page = output_is_Page.tolist()\n",
    "        \n",
    "        t_NumOfPage = []\n",
    "        for m in NumOfPage:\n",
    "            t_NumOfPage.append(m)\n",
    "        NumOfPage_arr2d = np.matrix(f_is_Page)\n",
    "        NumOfPage_to_add = np.array(t_NumOfPage)\n",
    "        output_NumOfPage = np.column_stack((NumOfPage_arr2d, NumOfPage_to_add))\n",
    "        f_NumOfPage = output_NumOfPage.tolist()\n",
    "        \n",
    "        t_NumberOfValues = []\n",
    "        for m in NumberOfValues:\n",
    "            t_NumberOfValues.append(m)\n",
    "        NumberOfValues_arr2d = np.matrix(f_NumOfPage)\n",
    "        NumberOfValues_to_add = np.array(t_NumberOfValues)\n",
    "        output_NumberOfValues = np.column_stack((NumberOfValues_arr2d, NumberOfValues_to_add))\n",
    "        f_NumberOfValues = output_NumberOfValues.tolist()\n",
    "        \n",
    "        t_navType = []\n",
    "        for m in navType:\n",
    "            t_navType.append(m)\n",
    "        navType_arr2d = np.matrix(f_NumberOfValues)\n",
    "        navType_to_add = np.array(t_navType)\n",
    "        output_navType = np.column_stack((navType_arr2d, navType_to_add))\n",
    "        f_navType = output_navType.tolist()\n",
    "        \n",
    "        t_pageClass = []\n",
    "        for m in pageClass:\n",
    "            t_pageClass.append(m)\n",
    "        pageClass_arr2d = np.matrix(f_navType)\n",
    "        pageClass_to_add = np.array(t_pageClass)\n",
    "        output_pageClass = np.column_stack((pageClass_arr2d, pageClass_to_add))\n",
    "        f_pageClass = output_pageClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_pageClass)\n",
    "        column_name = np.array(name_url)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        hours, rem = divmod(end-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"\\nTime takes: {:0>2}:{:0>2}:{:05.2f} Seconds\\n\".format(int(hours),int(minutes),seconds))\n",
    "        return f_name\n",
    "    \n",
    "def write_header():\n",
    "    list_of_header = [\"NumOfButton\", \"NumOfLinks\", \"commonURL\",\"is_page\", \"NumOfPage\", \"NumberOfValues\",\"navType\",\"pageClass\", \"name_url\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"page_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"page_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a54bb",
   "metadata": {},
   "source": [
    "### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e903942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    \n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    selectSearch = soup.findAll('select',{\"data-attribute\":\"sort\"})\n",
    "    ulSearch = soup.findAll('ul',{\"data-attribute\":\"sort\"})\n",
    "    '''\n",
    "    divSearch = soup.findAll('div',{\"data-attribute\":\"sort\"})\n",
    "    if not divSearch:\n",
    "        print(\"No Div\")\n",
    "    else:\n",
    "        print(\"Div\")\n",
    "    '''\n",
    "    if not ulSearch:\n",
    "        print(\"No UL\")\n",
    "    else:\n",
    "        print(\"UL\") \n",
    "    if not selectSearch:\n",
    "        print(\"No Select\")\n",
    "    else:\n",
    "        print(\"Select\")  \n",
    "    #print(soup.findAll(text=re.compile('^Sort By$')))\n",
    "    #print(len(soup.findAll(text=re.compile(\".*sort .*\"))))\n",
    "\n",
    "    if selectSearch != []:\n",
    "        #print(\"Select\")\n",
    "        for tests in soup.findAll('select'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()):\n",
    "                if \"sort\" in list(tests.attrs.values()):\n",
    "                    sortClass.append(1)\n",
    "                else:\n",
    "                    sortClass.append(0)\n",
    "            else:\n",
    "                sortClass.append(0)\n",
    "            if \" \" == tests.text:\n",
    "                sort_inner.append(0)             \n",
    "            else:\n",
    "                #print(tests.text)\n",
    "                if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                    #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                    sort_inner.append(1)\n",
    "                else:\n",
    "                    sort_inner.append(0)             \n",
    "            if('sort' in list(tests.attrs.values())):\n",
    "                #print(tests.attrs.values())\n",
    "                sort_attribute.append(1)\n",
    "            else:\n",
    "                sort_attribute.append(0) \n",
    "            optionTag = tests.findAll(\"option\")\n",
    "            option_tag_attribute_value.append(len(optionTag))\n",
    "    elif ulSearch != []:\n",
    "        #print(\"UL\")\n",
    "        for tests in soup.findAll('ul'):\n",
    "            t_Price = len(tests.findAll(text=re.compile(\".*Price.*\"))) \n",
    "            t_Most = len(tests.findAll(text=re.compile(\".*Most recent.*\")))\n",
    "            t_New = len(tests.findAll(text=re.compile(\".*New.*\")))\n",
    "            t_Best = len(tests.findAll(text=re.compile(\".*Best Match.*\")))  \n",
    "            t_Highest = len(tests.findAll(text=re.compile(\".*Highest*\"))) \n",
    "            t_Ratings = len(tests.findAll(text=re.compile(\".*Ratings.*\"))) \n",
    "            t_Distance = len(tests.findAll(text=re.compile(\".*Distance*\"))) \n",
    "            t_Time = len(tests.findAll(text=re.compile(\".*Time*\"))) \n",
    "            t_Relevance = len(tests.findAll(text=re.compile(\".*Relevance*\"))) \n",
    "            t_Featured = len(tests.findAll(text=re.compile(\".*Featured.*\"))) \n",
    "            t_Recommended = len(tests.findAll(text=re.compile(\".*Recommended.*\")))\n",
    "            t_count.append((int(t_Price)+int(t_Most)+int(t_New)+int(t_Best)+int(t_Highest)+int(t_Ratings)+int(t_Distance)+int(t_Time)+int(t_Relevance)+int(t_Featured)+int(t_Recommended)))\n",
    "            if \"data-attribute\" in list(tests.attrs.keys()):\n",
    "                if \"sort\" in list(tests.attrs.values()):\n",
    "                    sortClass.append(1)\n",
    "                else:\n",
    "                    sortClass.append(0)\n",
    "            else:\n",
    "                sortClass.append(0)\n",
    "            if \" \" == tests.text:\n",
    "                sort_inner.append(0)             \n",
    "            else:\n",
    "                #print(tests.text)\n",
    "                if (t_Price or t_Most or t_New or t_Best or  t_Highest or t_Ratings or t_Distance or t_Time or t_Relevance or t_Featured or t_Recommended)!=0:\n",
    "                    #print(tests(text=lambda t: \"sort:\" in t))\n",
    "                    sort_inner.append(1)\n",
    "                else:\n",
    "                    sort_inner.append(0)             \n",
    "            if('sort' in list(tests.attrs.values())):\n",
    "                #print(tests.attrs.values())\n",
    "                sort_attribute.append(1)\n",
    "            else:\n",
    "                sort_attribute.append(0) \n",
    "            optionTag = tests.findAll(\"li\")\n",
    "            option_tag_attribute_value.append(len(optionTag))\n",
    "    else:\n",
    "        sortClass.append(0)\n",
    "        sort_inner.append(0)\n",
    "        option_tag_attribute_value.append(0)\n",
    "        sort_attribute.append(0)\n",
    "    if (sort_inner ==[]):\n",
    "        sort_inner = [0]\n",
    "    if (sort_attribute ==[]):\n",
    "        sort_attribute = [0]\n",
    "    if (option_tag_attribute_value ==[]):\n",
    "        option_tag_attribute_value = [0]\n",
    "    if (sortClass ==[]):\n",
    "        sortClass = [0]\n",
    "    if (t_count ==[]):\n",
    "        t_count = [0]    \n",
    "    temp = len(sort_inner)*[_url_]\n",
    "    \n",
    "    return temp, sort_inner,  option_tag_attribute_value, sort_attribute, sortClass,t_count\n",
    "\n",
    "def get_class_data(searchQ) :\n",
    "        name_url, sort_inner, option_tag_attribute_value, sort_attribute, sortClass, textCount = sortFunc(searchQ)\n",
    "        sort_inner = str(sort_inner)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        sort_attribute = str(sort_attribute)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #option_tag_attribute_value = str(option_tag_attribute_value)[1:-1]\n",
    "        sortClass = str(sortClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in sort_inner:\n",
    "            sort_inner = i\n",
    "            temp.append([sort_inner])        \n",
    "        \n",
    "        t_sort_attribute = []\n",
    "        for m in sort_attribute:\n",
    "            t_sort_attribute.append(m)\n",
    "        arr2d = np.matrix(temp)\n",
    "        column_to_add = np.array(t_sort_attribute)\n",
    "        output = np.column_stack((arr2d, column_to_add))\n",
    "        f_sort_attribute = output.tolist()\n",
    "        \n",
    "        t_option = []\n",
    "        for m in option_tag_attribute_value:\n",
    "            t_option.append(m)\n",
    "        option_arr2d = np.matrix(f_sort_attribute)\n",
    "        option_to_add = np.array(t_option)\n",
    "        output_option = np.column_stack((option_arr2d, option_to_add))\n",
    "        f_option = output_option.tolist()\n",
    "\n",
    "        t_sortClass = []\n",
    "        for m in sortClass:\n",
    "            t_sortClass.append(m)\n",
    "        sortClass_arr2d = np.matrix(f_option)\n",
    "        sortClass_add = np.array(t_sortClass)\n",
    "        sortClass_output = np.column_stack((sortClass_arr2d, sortClass_add))\n",
    "        f_sortClass = sortClass_output.tolist()\n",
    "        \n",
    "        t_textCount = []\n",
    "        for m in textCount:\n",
    "            t_textCount.append(m)\n",
    "        textCount_arr2d = np.matrix(f_sortClass)\n",
    "        textCount_add = np.array(t_textCount)\n",
    "        textCount_output = np.column_stack((textCount_arr2d, textCount_add))\n",
    "        f_textCount = textCount_output.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_textCount)\n",
    "        column_name = np.array(t_name)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "\n",
    "        return f_name\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"sort_inner\", \"sort_attribute\", \"option_tag_attribute_value\",\"sortClass\",\"textCount\",\"name_url\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"sort_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"sort_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a7606",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFunc(_url_):\n",
    "    sort_inner, sortClass,option_tag_attribute_value, sort_attribute,t_count  = ([] for i in range(5)) \n",
    "    \n",
    "    myFile=open(_url_,'r',encoding=\"latin-1\")\n",
    "    soup=BeautifulSoup(myFile,\"html5lib\")\n",
    "    \n",
    "    divFilter, ulFilter, liFilter, formFilter, sectionFilter, fieldsetFilter, dtFilter,\\\n",
    "    buttonFilter,articleFilter,dlFilter,desktopfacetFilter = \\\n",
    "    soup.findAll('div',{\"data-attribute\":\"filter\"}),soup.findAll('ul',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('li',{\"data-attribute\":\"filter\"}), soup.findAll('form',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('section',{\"data-attribute\":\"filter\"}), soup.findAll('fieldset',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('dt',{\"data-attribute\":\"filter\"}),soup.findAll('button',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('article',{\"data-attribute\":\"filter\"}), soup.findAll('dl',{\"data-attribute\":\"filter\"}),\\\n",
    "    soup.findAll('desktop-facet',{\"data-attribute\":\"filter\"})\n",
    "    try:\n",
    "        if divFilter != []:    \n",
    "            div_name_url, div_checkBoxList, div_NumberOfLink, div_NumberOfInput, div_URL_List, div_button_List, div_filterClass = filter_Extract(soup, 'div',_url_)\n",
    "            return div_name_url, div_checkBoxList, div_NumberOfLink, div_NumberOfInput, div_URL_List, div_button_List, div_filterClass\n",
    "        if liFilter != []:    \n",
    "            li_name_url,  li_checkBoxList,  li_NumberOfLink,  li_NumberOfInput,  li_URL_List, li_button_List, li_filterClass = filter_Extract(soup, 'li',_url_)\n",
    "            return li_name_url,  li_checkBoxList,  li_NumberOfLink,  li_NumberOfInput, li_URL_List, li_button_List, li_filterClass\n",
    "        if buttonFilter != []:    \n",
    "            button_name_url, button_checkBoxList, button_NumberOfLink, button_NumberOfInput, button_URL_List, button_button_List, button_filterClass = filter_Extract(soup, 'button',_url_)\n",
    "            return button_name_url, button_checkBoxList, button_NumberOfLink, button_NumberOfInput, button_URL_List, button_button_List, button_filterClass\n",
    "        if dlFilter != []:    \n",
    "            dl_name_url, dl_checkBoxList, dl_NumberOfLink, dl_NumberOfInput, dl_URL_List, dl_button_List, dl_filterClass = filter_Extract(soup, 'dl',_url_)\n",
    "            return dl_name_url, dl_checkBoxList, dl_NumberOfLink, dl_NumberOfInput, dl_URL_List, dl_button_List, dl_filterClass \n",
    "        if desktopfacetFilter != []:    \n",
    "            df_name_url, df_checkBoxList, df_NumberOfLink, df_NumberOfInput, df_URL_List, df_button_List, df_filterClass = filter_Extract(soup, 'desktop-facet',_url_)\n",
    "            return df_name_url, df_checkBoxList, df_NumberOfLink, df_NumberOfInput, df_URL_List, df_button_List, df_filterClass\n",
    "        if articleFilter != []:    \n",
    "            art_name_url, art_checkBoxList, art_NumberOfLink, art_NumberOfInput, art_URL_List, art_button_List, art_filterClass = filter_Extract(soup, 'article',_url_)\n",
    "            return art_name_url, art_checkBoxList, art_NumberOfLink, art_NumberOfInput, art_URL_List, art_button_List, art_filterClass\n",
    "        if dtFilter != []:    \n",
    "            dt_name_url, dt_checkBoxList, dt_NumberOfLink, dt_NumberOfInput, dt_URL_List, dt_button_List, dt_filterClass = filter_Extract(soup, 'dt',_url_)\n",
    "            return dt_name_url, dt_checkBoxList, dt_NumberOfLink, dt_NumberOfInput, dt_URL_List, dt_button_List, dt_filterClass \n",
    "        if fieldsetFilter != []:    \n",
    "            f_name_url, f_checkBoxList, f_NumberOfLink, f_NumberOfInput, f_URL_List, f_button_List, f_filterClass = filter_Extract(soup, 'fieldset',_url_)\n",
    "            return f_name_url, f_checkBoxList, f_NumberOfLink, f_NumberOfInput, f_URL_List, f_button_List, f_filterClass\n",
    "        if sectionFilter != []:    \n",
    "            s_name_url, s_checkBoxList, s_NumberOfLink, s_NumberOfInput, s_URL_List, s_button_List, s_filterClass = filter_Extract(soup, 'section',_url_)\n",
    "            return s_name_url, s_checkBoxList, s_NumberOfLink, s_NumberOfInput, s_URL_List, s_button_List, s_filterClass\n",
    "        if formFilter != []:    \n",
    "            form_name_url, form_checkBoxList, form_NumberOfLink, form_NumberOfInput, form_URL_List, form_button_List, form_filterClass = filter_Extract(soup, 'form',_url_)\n",
    "            return form_name_url, form_checkBoxList, form_NumberOfLink, form_NumberOfInput, form_URL_List, form_button_List, form_filterClass\n",
    "        if ulFilter != []:    \n",
    "            ul_name_url, ul_checkBoxList, ul_NumberOfLink, ul_NumberOfInput, ul_URL_List, ul_button_List, ul_filterClass = filter_Extract(soup, 'ul',_url_)\n",
    "            return ul_name_url, ul_checkBoxList, ul_NumberOfLink, ul_NumberOfInput, ul_URL_List, ul_button_List, ul_filterClass\n",
    "        else:\n",
    "            return _url_,\"0\",\"0\",\"0\",\"0\",\"0\",\"1\"\n",
    "    except:\n",
    "        pass\n",
    "def filter_Extract(soup, tag,_url_):\n",
    "    fCount  = 0\n",
    "    filterClass, checkBoxList,insideList,outerList, NumberOfFilter, NumberOfLink, temp2,\\\n",
    "    NumberOfInput, URL_List, button_List = [], [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    for ele in soup.findAll(tag):\n",
    "                if \"data-attribute\" in list(ele.attrs.keys()) and \"filter\" in list(ele.attrs.values()):\n",
    "                        #======================= filterClass =======================\n",
    "                        filterClass.append(1)\n",
    "                        fCount +=1\n",
    "                        ch1 = 0\n",
    "                       \n",
    "                        #======================= Sub-Category ======================= \n",
    "                        child = 0\n",
    "                        for scat in ele.findAll('label'):\n",
    "                            child +=1\n",
    "                            #print(scat.text)\n",
    "                        insideList.append(child)\n",
    "                        #========================= CheckBox =========================             \n",
    "                        for chk in ele.findAll('input', {\"type\": \"checkbox\"}):\n",
    "                            pass\n",
    "                            ch1 += 1\n",
    "                        if ch1 !=0 and ch1 !=1:\n",
    "                            pass\n",
    "                            #print(ch1)\n",
    "                            checkBoxList.append(1)\n",
    "                        elif ch1 is None:\n",
    "                            pass\n",
    "                            #print(\"Empty\")\n",
    "                        else:\n",
    "                            checkBoxList.append(0)\n",
    "                      \n",
    "                        #=================== Number of link used =================== \n",
    "                        valueCounter =0\n",
    "                        for link in ele.findAll('a'):\n",
    "                            valueCounter += 1\n",
    "                        NumberOfLink.append(valueCounter)\n",
    "                        #=================== Number of inputbox =================== \n",
    "                        inputCounter = 0\n",
    "                        for link in ele.findAll('input'):\n",
    "                            inputCounter += 1\n",
    "                        NumberOfInput.append(inputCounter)\n",
    "                        #=================== Number of URL List =================== \n",
    "                        linkCount = 0\n",
    "                        for alink in ele.findAll('a', href=True):\n",
    "                            linkCount += 1\n",
    "                        URL_List.append(1)\n",
    "                        #=================== Number of button List =================== \n",
    "                        buttonCount = 0\n",
    "                        for btn in ele.findAll('button'):\n",
    "                            buttonCount += 1\n",
    "                        if buttonCount!=1:\n",
    "                            button_List.append(1)\n",
    "                        else:\n",
    "                            button_List.append(0)\n",
    "                else:\n",
    "                    filterClass.append(0)\n",
    "                    checkBoxList.append(0)  \n",
    "                    NumberOfLink.append(0)\n",
    "                    NumberOfInput.append(0)\n",
    "                    URL_List.append(0)\n",
    "                    button_List.append(0)\n",
    "\n",
    "    name_url = len(filterClass)*[_url_]\n",
    "    if (NumberOfLink ==[] or NumberOfLink is None):\n",
    "        NumberOfLink = [0]\n",
    "    if (NumberOfInput ==[] or NumberOfInput is None):\n",
    "        NumberOfInput = [0] \n",
    "    if (checkBoxList ==[] or checkBoxList is None):\n",
    "        checkBoxList = [0]\n",
    "    if (URL_List ==[] or URL_List is None):\n",
    "        URL_List = [0]\n",
    "    if (button_List ==[] or button_List is None):\n",
    "        button_List = [0]\n",
    "    if (filterClass == [] or filterClass is None):\n",
    "        filterClass = [1]\n",
    "    #print(len(filterClass))\n",
    "    #print(len(checkBoxList))\n",
    "    #print(len(NumberOfLink))\n",
    "    #print(len(NumberOfInput))\n",
    "    #print(len(URL_List))\n",
    "    #print(len(button_List))\n",
    "    return name_url, checkBoxList, NumberOfLink, NumberOfInput, URL_List, button_List, filterClass\n",
    "def get_class_data(searchQ) :\n",
    "        start_time= time.time()\n",
    "        name_url, checkBoxList, NumberOfLink, NumberOfInput, URL_List, button_List, filterClass = filterFunc(searchQ)\n",
    "        #checkBoxList = str(checkBoxList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #insideList = str(insideList)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "        #filterClass = str(filterClass)[1:-1].replace(\",\",\"\").replace(\" \",\"\")\n",
    "\n",
    "        \n",
    "        temp = []\n",
    "        temp2 = []\n",
    "        for i in checkBoxList:\n",
    "            checkBoxList = i\n",
    "            temp.append([checkBoxList])        \n",
    "        \n",
    "        t_NumberOfLink= []\n",
    "        for m in NumberOfLink:\n",
    "            t_NumberOfLink.append(m)\n",
    "        NumOfLinks_arr2d = np.matrix(temp)\n",
    "        NumOfLinks_to_add = np.array(t_NumberOfLink)\n",
    "        output_NumOfLinks = np.column_stack((NumOfLinks_arr2d, NumOfLinks_to_add))\n",
    "        f_NumOfLinks = output_NumOfLinks.tolist()\n",
    "        \n",
    "        t_NumberOfInput = []\n",
    "        for m in NumberOfInput:\n",
    "            t_NumberOfInput.append(m)\n",
    "        NumberOfInput_arr2d = np.matrix(f_NumOfLinks)\n",
    "        NumberOfInput_to_add = np.array(t_NumberOfInput)\n",
    "        output_NumberOfInput = np.column_stack((NumberOfInput_arr2d, NumberOfInput_to_add))\n",
    "        f_NumberOfInput = output_NumberOfInput.tolist()\n",
    "        \n",
    "        t_URL_List = []\n",
    "        for m in URL_List:\n",
    "            t_URL_List.append(m)\n",
    "        URL_List_arr2d = np.matrix(f_NumberOfInput)\n",
    "        URL_List_to_add = np.array(t_URL_List)\n",
    "        output_URL_List = np.column_stack((URL_List_arr2d, URL_List_to_add))\n",
    "        f_URL_List= output_URL_List.tolist()\n",
    "        \n",
    "        t_button_List = []\n",
    "        for m in button_List:\n",
    "            t_button_List.append(m)\n",
    "        button_List_arr2d = np.matrix(f_URL_List)\n",
    "        button_List_to_add = np.array(t_button_List)\n",
    "        output_button_List = np.column_stack((button_List_arr2d, button_List_to_add))\n",
    "        f_button_List= output_button_List.tolist()\n",
    "        \n",
    "        t_filterClass = []\n",
    "        for m in filterClass:\n",
    "            t_filterClass.append(m)\n",
    "        filterClass_arr2d = np.matrix(f_button_List)\n",
    "        filterClass_to_add = np.array(t_filterClass)\n",
    "        output_filterClass = np.column_stack((filterClass_arr2d, filterClass_to_add))\n",
    "        f_filterClass = output_filterClass.tolist()\n",
    "        \n",
    "        t_name= []\n",
    "        for m in name_url:\n",
    "            t_name.append(m)\n",
    "        a_name = np.matrix(f_filterClass)\n",
    "        column_name = np.array(name_url)\n",
    "        o_name = np.column_stack((a_name, column_name))\n",
    "        f_name= o_name.tolist()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        hours, rem = divmod(end-start_time, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"\\nTime takes: {:0>2}:{:0>2}:{:05.2f} Seconds\\n\".format(int(hours),int(minutes),seconds))\n",
    "        return f_name\n",
    "\n",
    "\n",
    "def write_header():\n",
    "    list_of_header = [\"checkBoxList\", \"NumberOfLink\",\"NumberOfInput\", \"URL_List\", \"button_List\",\"filterClass\", \"name_url\"]\n",
    "    save_path = 'result/'\n",
    "    file_name = \"filter_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(list_of_header)\n",
    "\n",
    "def write_CSV(tlist):\n",
    "    save_path = 'result/'\n",
    "    file_name = \"filter_test_set_1.csv\"\n",
    "    completeName = os.path.join(save_path, file_name)\n",
    "    with open(completeName, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(tlist)\n",
    "    with open(completeName, \"r\", newline=\"\") as fr:\n",
    "        reader = csv.reader(fr)\n",
    "        lines= len(list(reader))\n",
    "        print(\"[\",lines,\"].\", \"form!\")\n",
    "\n",
    "def main():\n",
    "    write_header()\n",
    "    for i in range(0,100):\n",
    "            print(write_CSV(get_class_data(turl[i])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7af70806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(Search_X_test,Search_y_test,searchname,target_names):\n",
    "    p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "    searchname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/search_model.sav\"\n",
    "    search_model = pickle.load(open(searchname, 'rb'))\n",
    "    y_score = search_model.predict(Search_X_test)\n",
    "    precision = precision_score(Search_y_test, y_score, average=None)\n",
    "    p_class_0.append(precision[0])\n",
    "    p_class_1.append(precision[1])\n",
    "    recall = recall_score(Search_y_test, y_score, average=None)\n",
    "    r_class_0.append(recall[0])\n",
    "    r_class_1.append(recall[1])\n",
    "    print(\"===================\",target_names[1],\"===================\")\n",
    "    print('Average class ',target_names[0],' precision = {:.2f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "    print('Average class ',target_names[1],' precision = {:.2f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "    print('Average class ',target_names[0],' recall = {:.2f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "    print('Average class ',target_names[1],' recall = {:.2f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "    print('Accuracy: {:.2f}'.format(accuracy_score(Search_y_test, y_score)*100))\n",
    "    print(classification_report(Search_y_test, y_score, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea36b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Search ===================\n",
      "Average class  Non-Search  precision = 96.65\n",
      "Average class  Search  precision = 39.53\n",
      "Average class  Non-Search  recall = 94.34\n",
      "Average class  Search  recall = 53.12\n",
      "Accuracy: 91.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Search       0.97      0.94      0.95       459\n",
      "      Search       0.40      0.53      0.45        32\n",
      "\n",
      "    accuracy                           0.92       491\n",
      "   macro avg       0.68      0.74      0.70       491\n",
      "weighted avg       0.93      0.92      0.92       491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Search_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/SearchList_test_set_1.csv'\n",
    "Search_csv_df = pd.read_csv(Search_searchpath)\n",
    "Search_X_test = Search_csv_df[[\"search_innertext\", \"search_attribute\", \"Number_of_search_word\",\"search_button_attribute_value\",\"is_button\"]]\n",
    "Search_y_test = Search_csv_df[[\"sClass\"]]\n",
    "searchname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/search_model.sav\"\n",
    "target_names = ['Non-Search', 'Search']\n",
    "evaluation(Search_X_test,Search_y_test,searchname,target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de75cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Filter ===================\n",
      "Average class  Non-Filter  precision = 99.77\n",
      "Average class  Filter  precision = 100.00\n",
      "Average class  Non-Filter  recall = 100.00\n",
      "Average class  Filter  recall = 54.66\n",
      "Accuracy: 99.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Filter       1.00      1.00      1.00    151373\n",
      "      Filter       1.00      0.55      0.71       761\n",
      "\n",
      "    accuracy                           1.00    152134\n",
      "   macro avg       1.00      0.77      0.85    152134\n",
      "weighted avg       1.00      1.00      1.00    152134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/filter_test_set_1.csv'\n",
    "filter_csv_df = pd.read_csv(filter_searchpath)\n",
    "filter_X_test = filter_csv_df[[\"checkBoxList\", \"NumberOfLink\",\"NumberOfInput\", \"URL_List\", \"button_List\"]]\n",
    "filter_y_test = filter_csv_df[[\"filterClass\"]]\n",
    "filtername = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/filter_model.sav\"\n",
    "target_names = ['Non-Filter', 'Filter']\n",
    "evaluation(filter_X_test,filter_y_test,filtername,target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8325bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Sort ===================\n",
      "Average class  Non-sort  precision = 100.00\n",
      "Average class  Sort  precision = 5.42\n",
      "Average class  Non-sort  recall = 63.38\n",
      "Average class  Sort  recall = 100.00\n",
      "Accuracy: 64.13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-sort       1.00      0.63      0.78       953\n",
      "        Sort       0.05      1.00      0.10        20\n",
      "\n",
      "    accuracy                           0.64       973\n",
      "   macro avg       0.53      0.82      0.44       973\n",
      "weighted avg       0.98      0.64      0.76       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sort_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/sort_test_set_1.csv'\n",
    "sort_csv_df = pd.read_csv(sort_searchpath)\n",
    "sort_X_test = sort_csv_df[['sort_inner','sort_attribute','option_tag_attribute_value','textCount']]\n",
    "sort_y_test = sort_csv_df[[\"sortClass\"]]\n",
    "sortname = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/sort_model.sav\"\n",
    "\n",
    "p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "sort_model = pickle.load(open(sortname, 'rb'))\n",
    "sort_score = sort_model.predict(sort_X_test)\n",
    "precision = precision_score(sort_y_test, sort_score, average=None)\n",
    "p_class_0.append(precision[0])\n",
    "p_class_1.append(precision[1])\n",
    "recall = recall_score(sort_y_test, sort_score, average=None)\n",
    "r_class_0.append(recall[0])\n",
    "r_class_1.append(recall[1])\n",
    "print(\"===================\",target_names[1],\"===================\")\n",
    "print('Average class ',target_names[0],' precision = {:.2f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "print('Average class ',target_names[1],' precision = {:.2f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "print('Average class ',target_names[0],' recall = {:.2f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "print('Average class ',target_names[1],' recall = {:.2f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(sort_y_test, sort_score)*100))\n",
    "target_names = ['Non-sort', 'Sort']\n",
    "print(classification_report(sort_y_test, sort_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8890712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54762 entries, 0 to 54761\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   NumOfButton     54762 non-null  int64\n",
      " 1   NumOfLinks      54762 non-null  int64\n",
      " 2   commonURL       54762 non-null  int64\n",
      " 3   is_page         54762 non-null  int64\n",
      " 4   NumOfPage       54762 non-null  int64\n",
      " 5   NumberOfValues  54762 non-null  int64\n",
      " 6   navType         54762 non-null  int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 2.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "page_searchpath = '/Users/mdjavedulferdous/Desktop/TiiS/Code/result/page_test_set_1.csv'\n",
    "page_csv_df = pd.read_csv(page_searchpath)\n",
    "page_X_test = page_csv_df[['NumOfButton','NumOfLinks','commonURL','is_page','NumOfPage','NumberOfValues','navType']]\n",
    "page_y_test = page_csv_df[[\"pageClass\"]]\n",
    "pagename = \"/Users/mdjavedulferdous/Desktop/TiiS/Code/page_model.sav\"\n",
    "print(page_X_test.info())\n",
    "\n",
    "p_class_0, p_class_1, r_class_0, r_class_1 = [], [], [], []\n",
    "page_model = pickle.load(open(pagename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0cdeb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54762 entries, 0 to 54761\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   NumOfButton     54762 non-null  int64\n",
      " 1   NumOfLinks      54762 non-null  int64\n",
      " 2   commonURL       54762 non-null  int64\n",
      " 3   is_page         54762 non-null  int64\n",
      " 4   NumOfPage       54762 non-null  int64\n",
      " 5   NumberOfValues  54762 non-null  int64\n",
      " 6   navType         54762 non-null  int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "page_X_test.info()\n",
    "page_score = page_model.predict(page_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c6793fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Page ===================\n",
      "Average class  Non-Page  precision = 99.96\n",
      "Average class  Page  precision = 68.47\n",
      "Average class  Non-Page  recall = 87.79\n",
      "Average class  Page  recall = 76.67\n",
      "Accuracy: 99.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Page       1.00      1.00      1.00     54662\n",
      "        Page       1.00      0.65      0.79       100\n",
      "\n",
      "    accuracy                           1.00     54762\n",
      "   macro avg       1.00      0.82      0.89     54762\n",
      "weighted avg       1.00      1.00      1.00     54762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(page_y_test, page_score, average=None)\n",
    "p_class_0.append(precision[0])\n",
    "p_class_1.append(precision[1])\n",
    "recall = recall_score(page_y_test, page_score, average=None)\n",
    "r_class_0.append(recall[0])\n",
    "r_class_1.append(recall[1])\n",
    "print(\"===================\",target_names[1],\"===================\")\n",
    "\n",
    "print('Average class ',target_names[0],' precision = {:.2f}'.format((sum(p_class_0)/len(p_class_0))*100))\n",
    "print('Average class ',target_names[1],' precision = {:.2f}'.format((sum(p_class_1)/len(p_class_1))*100))\n",
    "print('Average class ',target_names[0],' recall = {:.2f}'.format((sum(r_class_0)/len(r_class_0))*100))\n",
    "print('Average class ',target_names[1],' recall = {:.2f}'.format((sum(r_class_1)/len(r_class_1))*100))\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(page_y_test, page_score)*100))\n",
    "target_names = ['Non-Page', 'Page']\n",
    "print(classification_report(page_y_test, page_score, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed526b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
